{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  Urdu Conversational Chatbot (Encoderâ€“Decoder Transformer) â€” From Scratch  \n",
        "\n",
        "**Objective:**  \n",
        "Build and train a **complete Urdu conversational chatbot** using the **Transformer Encoderâ€“Decoder architecture** implemented **entirely from scratch in PyTorch**, without using any pre-trained models.  \n",
        "The chatbot learns to generate **context-aware Urdu replies** by automatically constructing `(source â†’ target)` pairs from conversational transcripts.\n",
        "\n",
        "---\n",
        "\n",
        "**Whatâ€™s inside**  \n",
        "- ğŸ”¤ **SentencePiece (BPE)** tokenizer for subword-level Urdu tokenization  \n",
        "- âš™ï¸ **Data pipeline:** loading, normalization, and automated conversational pair creation  \n",
        "- ğŸ§© **Transformer model components:**  \n",
        "  - **Encoder** â€“ captures contextual meaning from input sentences  \n",
        "  - **Decoder** â€“ generates Urdu responses step-by-step  \n",
        "  - **Multi-Head Attention**, **Positional Encoding**, and **Feed-Forward layers**  \n",
        "- ğŸ§® **Training setup:**  \n",
        "  - Teacher forcing with **padding & causal masks**  \n",
        "  - **Cross-Entropy Loss** with Label Smoothing  \n",
        "  - Evaluation using **BLEU**, **ROUGE-L**, and **chrF** metrics  \n",
        "- ğŸ’¬ **Interactive Gradio chatbot** for real-time Urdu dialogue generation  \n",
        "- ğŸ§  **Fully explainable pipeline** â€” no hidden pretrained components\n",
        "\n",
        "---\n",
        "\n",
        "**Workflow Overview**  \n",
        "1. **Data Loading & Cleaning:** Import Urdu dataset (TSV/CSV/TXT), normalize Alef/Ye, and remove diacritics.  \n",
        "2. **Pair Construction:** Form `(src â†’ dst)` pairs using previous-line logic.  \n",
        "3. **Subword Tokenization:** Train SentencePiece BPE tokenizer to convert words â†’ token IDs.  \n",
        "4. **Transformer Model:** Convert token IDs to embeddings, add positional encodings, and train encoderâ€“decoder network.  \n",
        "5. **Training Loop:** Use teacher forcing with masks, optimize with Adam and gradient clipping.  \n",
        "6. **Evaluation:** Compute BLEU, chrF, ROUGE-L; visualize generated responses.  \n",
        "7. **Deployment:** Integrate Gradio UI for end-user Urdu chat experience.\n",
        "\n",
        "---\n",
        "\n",
        "**Expected Output**  \n",
        "-  A trained **Urdu chatbot** capable of generating contextual, meaningful replies.  \n",
        "- nsight into how the **Transformer encoderâ€“decoder** handles sequence-to-sequence learning.  \n",
        "- ğŸ” A reusable modular notebook for chatbot projects in any low-resource language.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "j3WT_kCrJNZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 1 â€” Install Dependencies  \n",
        "\n",
        "**Purpose:**  \n",
        "Install all required libraries for tokenization, evaluation, and interface deployment.  \n",
        "These include:  \n",
        "- `sentencepiece` â†’ subword tokenization (BPE)  \n",
        "- `sacrebleu` & `rouge-score` â†’ text generation evaluation  \n",
        "- `gradio` â†’ chatbot web interface  \n"
      ],
      "metadata": {
        "id": "LSO9knN4J8co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sentencepiece sacrebleu rouge-score evaluate gradio==4.44.0\n"
      ],
      "metadata": {
        "id": "QALFKcmIKmhK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 2 â€” Import Libraries, Set Random Seed, and Detect Device  \n",
        "\n",
        "**Purpose:**  \n",
        "Import essential Python, PyTorch, and NLP modules,  \n",
        "set random seeds for reproducibility,  \n",
        "and detect whether GPU (CUDA) is available.  \n",
        "This ensures consistent results during multiple runs.  \n"
      ],
      "metadata": {
        "id": "F702Cf58KAoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, io, glob, zipfile, math, random, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sentencepiece as spm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "import gradio as gr\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR6RtkcBKr7X",
        "outputId": "23be4493-54b0-49df-9e67-9614e6f6c24b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 3 â€” Upload & Extract Urdu Dataset  \n",
        "\n",
        "**Purpose:**  \n",
        "Unzip the provided Urdu dataset (either `archive.zip` or `archeive.zip`) into `/content/data`.  \n",
        "This cell makes the data accessible for cleaning and preprocessing later.  \n",
        "\n",
        "**Notes:**  \n",
        "- Accepts `.zip` files uploaded to Colab.  \n",
        "- Prints all extracted files to verify dataset structure.  \n"
      ],
      "metadata": {
        "id": "7OwNATNIKBiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_candidates = [\"/content/final_main_dataset.tsv.zip\", \"/content/archeive.zip\"]\n",
        "zip_path = next((p for p in zip_candidates if os.path.exists(p)), None)\n",
        "if zip_path is None:\n",
        "    raise FileNotFoundError(\"Upload your dataset zip to /content as 'final_main_dataset.tsv.zip' or 'archeive.zip'.\")\n",
        "\n",
        "extract_dir = \"/content/data\"\n",
        "Path(extract_dir).mkdir(parents=True, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "print(\"Extracted files:\")\n",
        "for f in glob.glob(extract_dir + \"/**/*\", recursive=True):\n",
        "    if os.path.isfile(f): print(\"-\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNHo5PUzKtM3",
        "outputId": "c22d76da-6d36-47be-e737-7fc42d33f0a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files:\n",
            "- /content/data/final_main_dataset.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 4 â€” Load Dataset (TSV / CSV / TXT)  \n",
        "\n",
        "**Purpose:**  \n",
        "Automatically detect and load dataset format:  \n",
        "- `.tsv` â†’ tab-separated  \n",
        "- `.csv` â†’ comma-separated  \n",
        "- `.txt` â†’ one sentence per line  \n",
        "\n",
        "**Outcome:**  \n",
        "A pandas DataFrame containing Urdu sentences ready for text cleaning.  \n"
      ],
      "metadata": {
        "id": "7IecDuixKDwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tsv_files = glob.glob(os.path.join(extract_dir, \"**/*.tsv\"), recursive=True)\n",
        "csv_files = glob.glob(os.path.join(extract_dir, \"**/*.csv\"), recursive=True)\n",
        "txt_files = glob.glob(os.path.join(extract_dir, \"**/*.txt\"), recursive=True)\n",
        "\n",
        "data_file = None\n",
        "if tsv_files:   data_file = tsv_files[0]\n",
        "elif csv_files: data_file = csv_files[0]\n",
        "elif txt_files: data_file = txt_files[0]\n",
        "else: raise FileNotFoundError(\"No .tsv/.csv/.txt found inside the zip.\")\n",
        "\n",
        "print(\"Using:\", data_file)\n",
        "\n",
        "if data_file.endswith(\".tsv\"):\n",
        "    df = pd.read_csv(data_file, sep=\"\\t\", encoding=\"utf-8\", engine=\"python\")\n",
        "elif data_file.endswith(\".csv\"):\n",
        "    df = pd.read_csv(data_file, encoding=\"utf-8\")\n",
        "else:\n",
        "    lines = [l.strip() for l in open(data_file, encoding=\"utf-8\", errors=\"ignore\").read().splitlines()]\n",
        "    df = pd.DataFrame({\"sentence\": lines})\n",
        "\n",
        "print(df.head())\n",
        "print(\"Rows:\", len(df), \"Cols:\", df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV4Ls1wGK1cO",
        "outputId": "ef48be86-f5a7-4ef4-9445-80072e27c156"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: /content/data/final_main_dataset.tsv\n",
            "                                           client_id  \\\n",
            "0  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "1  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "2  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "3  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "4  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "\n",
            "                           path  \\\n",
            "0  common_voice_ur_31771683.mp3   \n",
            "1  common_voice_ur_31771684.mp3   \n",
            "2  common_voice_ur_31771685.mp3   \n",
            "3  common_voice_ur_31771730.mp3   \n",
            "4  common_voice_ur_31771732.mp3   \n",
            "\n",
            "                                            sentence  up_votes  down_votes  \\\n",
            "0                 Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº         2           0   \n",
            "1                  Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ         2           1   \n",
            "2                      ÛŒÛ ÙÛŒØµÙ„Û Ø¨Ú¾ÛŒ Ú¯Ø²Ø´ØªÛ Ø¯Ùˆ Ø³Ø§Ù„ Ù…ÛŒÚº         2           0   \n",
            "3                     Ø§Ù† Ú©Û’ Ø¨Ù„Û’ Ø¨Ø§Ø²ÙˆÚº Ú©Û’ Ø³Ø§Ù…Ù†Û’ ÛÙˆ Ú¯Ø§         3           0   \n",
            "4  Ø¢Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø¯ÙÙˆØ³Ù’Ø±Ø§ Ø¢Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´...         3           0   \n",
            "\n",
            "        age gender accents  variant locale  segment  \n",
            "0  twenties   male     NaN      NaN     ur      NaN  \n",
            "1  twenties   male     NaN      NaN     ur      NaN  \n",
            "2  twenties   male     NaN      NaN     ur      NaN  \n",
            "3  twenties   male     NaN      NaN     ur      NaN  \n",
            "4  twenties   male     NaN      NaN     ur      NaN  \n",
            "Rows: 20000 Cols: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 5 â€” Clean & Normalize Urdu Text  \n",
        "\n",
        "**Purpose:**  \n",
        "Standardize Urdu writing for consistent tokenization.  \n",
        "Removes diacritics, unifies Alef (Ø§) and Yeh (ÛŒ) variants,  \n",
        "and converts punctuation to common forms (ØŒ â†’ , , ØŸ â†’ ?).  \n",
        "\n",
        "**Why:**  \n",
        "Normalization reduces noise and improves vocabulary quality.  \n"
      ],
      "metadata": {
        "id": "ONZYl77NKF0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Urdu Text Normalization (Pro)\n",
        "# ===========================\n",
        "# Goals:\n",
        "# - Unicode normalize (NFKC) + strip zero-widths/tatweel\n",
        "# - Remove diacritics/Quranic marks safely\n",
        "# - Unify common Arabicâ†’Urdu letter variants\n",
        "# - Normalize punctuation (ØŒ Ø› Û” ØŸ) â†’ ASCII where useful\n",
        "# - Optional: convert Eastern digits â†’ Western (config)\n",
        "# - Preserve Urdu-specific contrasts (e.g., \"Û’\" NOT collapsed to \"ÛŒ\")\n",
        "\n",
        "import re, unicodedata\n",
        "\n",
        "# ---------- Config ----------\n",
        "NORMALIZE_PUNCT = True          # map Urdu punct to ASCII , ; . ?\n",
        "CONVERT_EASTERN_DIGITS = True   # Urdu \"Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹\" â†’ \"0123456789\"\n",
        "KEEP_ONLY_URDU_BLOCK = False    # if True: drop Latin/emoji/etc. (useful for very noisy corpora)\n",
        "\n",
        "\n",
        "ZW_RE   = re.compile(r\"[\\u200c\\u200d]\")        # ZWNJ, ZWJ\n",
        "TAT_RE  = re.compile(r\"\\u0640\")                # Tatweel (Ù€)\n",
        "\n",
        "DIAC_RE = re.compile(r\"[\\u064B-\\u0652\\u0670\\u0653-\\u065F\\u06D6-\\u06ED]\")\n",
        "\n",
        "LETTER_MAP = {\n",
        "    # Alef variants â†’ Ø§\n",
        "    \"Ø£\":\"Ø§\", \"Ø¥\":\"Ø§\", \"Ø¢\":\"Ø§\", \"Ù±\":\"Ø§\",\n",
        "    # Yeh variants â†’ ÛŒ\n",
        "    \"ÙŠ\":\"ÛŒ\", \"Ù‰\":\"ÛŒ\", \"Ø¦\":\"ÛŒ\", \"ÛŒÙ°\":\"ÛŒ\",\n",
        "    # Taa marbuta â†’ Û (Urdu heh goal)\n",
        "    \"Ø©\":\"Û\", \"Ûƒ\":\"Û\", \"Û€\":\"Û\", \"Ú¾\":\"Û\", \"ÛÙ°\":\"Û\",\n",
        "    # Kaf (Arabic) â†’ Ú© (Urdu)\n",
        "    \"Ùƒ\":\"Ú©\",\n",
        "    # Optional: hamza on waw (often safe to keep, but map if noisy)\n",
        "    \"Ø¤\":\"Ùˆ\",\n",
        "}\n",
        "\n",
        "PUNCT_MAP = {\n",
        "    \"ØŒ\": \",\",\n",
        "    \"Ø›\": \";\",\n",
        "    \"Û”\": \".\",\n",
        "    \"ØŸ\": \"?\",\n",
        "    \"Ù¬\": \",\",\n",
        "    \"Ù«\": \".\",\n",
        "    \"Â«\": '\"', \"Â»\": '\"', \"â€¹\": '\"', \"â€º\": '\"',\n",
        "}\n",
        "\n",
        "E2W = str.maketrans(\"Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹\", \"0123456789\")\n",
        "\n",
        "# Keep-only Urdu block (optional)\n",
        "NON_URDU_RE = re.compile(r\"[^\\u0600-\\u06FF\\s0-9A-Za-z\\.\\,\\;\\:\\?\\!\\-\\\"']\")  # allow basic ASCII if KEEP_ONLY_URDU_BLOCK=False\n",
        "JUST_URDU_RE = re.compile(r\"[^\\u0600-\\u06FF\\s]\")  # stricter\n",
        "\n",
        "def normalize_urdu(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1) Unicode normalization\n",
        "    s = unicodedata.normalize(\"NFKC\", text)\n",
        "\n",
        "    # 2) Remove zero-widths + tatweel\n",
        "    s = ZW_RE.sub(\"\", s)\n",
        "    s = TAT_RE.sub(\"\", s)\n",
        "\n",
        "    # 3) Remove diacritics/Quranic marks\n",
        "    s = DIAC_RE.sub(\"\", s)\n",
        "\n",
        "    # 4) Map Arabicâ†’Urdu letter variants\n",
        "    for src, dst in LETTER_MAP.items():\n",
        "        s = s.replace(src, dst)\n",
        "\n",
        "    # 5) Normalize punctuation & digits (configurable)\n",
        "    if NORMALIZE_PUNCT:\n",
        "        for k, v in PUNCT_MAP.items():\n",
        "            s = s.replace(k, v)\n",
        "    if CONVERT_EASTERN_DIGITS:\n",
        "        s = s.translate(E2W)\n",
        "\n",
        "    # 6) (Optional) keep-only Urdu block (useful for very noisy datasets)\n",
        "    if KEEP_ONLY_URDU_BLOCK:\n",
        "        s = JUST_URDU_RE.sub(\"\", s)\n",
        "    else:\n",
        "        # otherwise only strip unusual symbols (keep simple ASCII)\n",
        "        s = NON_URDU_RE.sub(\"\", s)\n",
        "\n",
        "    # 7) Collapse whitespace\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# ----- Apply to DataFrame -----\n",
        "# choose column\n",
        "text_col = \"clean_text\"\n",
        "base = (df[\"sentence\"] if \"sentence\" in df.columns else df.iloc[:, 0]).astype(str)\n",
        "df[text_col] = base.apply(normalize_urdu)\n",
        "df = df[df[text_col].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4ATCUtVK30s",
        "outputId": "3c8ce88e-6ac0-4adb-c9ec-8be48060818d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           client_id  \\\n",
            "0  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "1  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "2  e53f84d151d6cc6d45a57decde08a99efe47d7751a4ca6...   \n",
            "\n",
            "                           path                            sentence  up_votes  \\\n",
            "0  common_voice_ur_31771683.mp3  Ú©Ø¨Ú¾ÛŒ Ú©Ø¨Ú¾Ø§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº         2   \n",
            "1  common_voice_ur_31771684.mp3   Ø§ÙˆØ± Ù¾Ú¾Ø± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ú¾ÛŒ ÛÙˆ         2   \n",
            "2  common_voice_ur_31771685.mp3       ÛŒÛ ÙÛŒØµÙ„Û Ø¨Ú¾ÛŒ Ú¯Ø²Ø´ØªÛ Ø¯Ùˆ Ø³Ø§Ù„ Ù…ÛŒÚº         2   \n",
            "\n",
            "   down_votes       age gender accents  variant locale  segment  \\\n",
            "0           0  twenties   male     NaN      NaN     ur      NaN   \n",
            "1           1  twenties   male     NaN      NaN     ur      NaN   \n",
            "2           0  twenties   male     NaN      NaN     ur      NaN   \n",
            "\n",
            "                           clean_text  \n",
            "0  Ú©Ø¨ÛÛŒ Ú©Ø¨ÛØ§Ø± ÛÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù¾Ù„Ø§Ùˆ Ø¨Ù†Ø§ØªØ§ ÛÙˆÚº  \n",
            "1   Ø§ÙˆØ± Ù¾ÛØ± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛÛŒ ÛÙˆ  \n",
            "2       ÛŒÛ ÙÛŒØµÙ„Û Ø¨ÛÛŒ Ú¯Ø²Ø´ØªÛ Ø¯Ùˆ Ø³Ø§Ù„ Ù…ÛŒÚº  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\" PREPROCESSING QUALITY VERIFICATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================\n",
        "# 1. BASIC STATISTICS\n",
        "# ============================================================\n",
        "print(\"\\n 1. BASIC STATISTICS\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "original_col = \"sentence\"\n",
        "cleaned_col = \"clean_text\"\n",
        "\n",
        "print(f\"Total sentences: {len(df):,}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "\n",
        "# Length statistics\n",
        "orig_lengths = df[original_col].str.len()\n",
        "clean_lengths = df[cleaned_col].str.len()\n",
        "\n",
        "print(f\"\\n Text Length Statistics:\")\n",
        "print(f\"  Original - Min: {orig_lengths.min()}, Max: {orig_lengths.max()}, Mean: {orig_lengths.mean():.1f}\")\n",
        "print(f\"  Cleaned  - Min: {clean_lengths.min()}, Max: {clean_lengths.max()}, Mean: {clean_lengths.mean():.1f}\")\n",
        "print(f\"  Avg reduction: {(orig_lengths.mean() - clean_lengths.mean()):.1f} characters\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. CHARACTER ANALYSIS (FIXED)\n",
        "# ============================================================\n",
        "print(f\"\\nğŸ”¤ 2. CHARACTER SET ANALYSIS\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "def analyze_chars(text_series, label):\n",
        "    all_text = \" \".join(text_series.astype(str))\n",
        "    unique_chars = set(all_text)\n",
        "\n",
        "    # Categorize characters\n",
        "    urdu_chars = set()\n",
        "    arabic_chars = set()\n",
        "    digits = set()\n",
        "    punctuation = set()\n",
        "    latin = set()\n",
        "    other = set()\n",
        "\n",
        "    for char in unique_chars:\n",
        "        code = ord(char)\n",
        "        if 0x0600 <= code <= 0x06FF:  # Urdu/Arabic block\n",
        "            urdu_chars.add(char)\n",
        "        elif 0x0750 <= code <= 0x077F:  # Arabic supplement\n",
        "            arabic_chars.add(char)\n",
        "        elif char.isdigit():\n",
        "            digits.add(char)\n",
        "        elif char in \".,;:!?\\\"'()[]{}\":\n",
        "            punctuation.add(char)\n",
        "        elif char.isalpha() and ord(char) < 0x0600:\n",
        "            latin.add(char)\n",
        "        elif not char.isspace():\n",
        "            other.add(char)\n",
        "\n",
        "    print(f\"\\n{label}:\")\n",
        "    print(f\"  Unique characters: {len(unique_chars)}\")\n",
        "    print(f\"  Urdu/Arabic chars: {len(urdu_chars)}\")\n",
        "    print(f\"  Digits: {len(digits)} â†’ {sorted(digits)}\")\n",
        "    print(f\"  Punctuation: {len(punctuation)} â†’ {sorted(punctuation)}\")\n",
        "    print(f\"  Latin chars: {len(latin)} â†’ {sorted(latin) if latin else 'None'}\")\n",
        "    print(f\"  Other/Special: {len(other)} â†’ {sorted(other) if other else 'None'}\")\n",
        "\n",
        "    # FIXED: Return all sets for later use\n",
        "    return unique_chars, urdu_chars, arabic_chars, digits, punctuation, latin, other\n",
        "\n",
        "# Analyze both versions\n",
        "orig_chars, orig_urdu, orig_arabic, orig_digits, orig_punct, orig_latin, orig_other = analyze_chars(df[original_col], \"ORIGINAL TEXT\")\n",
        "clean_chars, clean_urdu, clean_arabic, clean_digits, clean_punct, clean_latin, clean_other = analyze_chars(df[cleaned_col], \"CLEANED TEXT\")\n",
        "\n",
        "removed_chars = orig_chars - clean_chars\n",
        "if removed_chars:\n",
        "    print(f\"\\n Removed characters ({len(removed_chars)}): {sorted(removed_chars)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. DIACRITICS CHECK\n",
        "# ============================================================\n",
        "print(f\"\\n 3. DIACRITICS VERIFICATION\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "diacritic_pattern = re.compile(r\"[\\u064B-\\u0652\\u0670\\u0653-\\u065F\\u06D6-\\u06ED]\")\n",
        "\n",
        "orig_with_diacritics = df[original_col].str.contains(diacritic_pattern, regex=True).sum()\n",
        "clean_with_diacritics = df[cleaned_col].str.contains(diacritic_pattern, regex=True).sum()\n",
        "\n",
        "print(f\"Sentences with diacritics:\")\n",
        "print(f\"  Original: {orig_with_diacritics:,} ({100*orig_with_diacritics/len(df):.1f}%)\")\n",
        "print(f\"  Cleaned:  {clean_with_diacritics:,} ({100*clean_with_diacritics/len(df):.1f}%)\")\n",
        "\n",
        "if clean_with_diacritics == 0:\n",
        "    print(\"   All diacritics removed successfully!\")\n",
        "else:\n",
        "    print(f\"   Warning: {clean_with_diacritics} sentences still have diacritics\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. NORMALIZATION CHECKS\n",
        "# ============================================================\n",
        "print(f\"\\n 4. NORMALIZATION VERIFICATION\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "checks = {\n",
        "    \"Alef variants (Ø£Ø¥Ø¢Ù±)\": r\"[Ø£Ø¥Ø¢Ù±]\",\n",
        "    \"Yeh variants (ÙŠÙ‰Ø¦)\": r\"[ÙŠÙ‰Ø¦]\",\n",
        "    \"Arabic Kaf (Ùƒ)\": r\"Ùƒ\",\n",
        "    \"Taa Marbuta (Ø©)\": r\"Ø©\",\n",
        "    \"Urdu comma (ØŒ)\": r\"ØŒ\",\n",
        "    \"Urdu question (ØŸ)\": r\"ØŸ\",\n",
        "    \"Eastern digits (Û°-Û¹)\": r\"[Û°-Û¹]\",\n",
        "    \"Tatweel (Ù€)\": r\"Ù€\",\n",
        "    \"Zero-width chars\": r\"[\\u200c\\u200d]\"\n",
        "}\n",
        "\n",
        "print(\"Checking for unnormalized characters:\")\n",
        "for name, pattern in checks.items():\n",
        "    orig_count = df[original_col].str.contains(pattern, regex=True).sum()\n",
        "    clean_count = df[cleaned_col].str.contains(pattern, regex=True).sum()\n",
        "\n",
        "    if orig_count > 0:\n",
        "        status = \"\" if clean_count == 0 else \"\"\n",
        "        print(f\"  {status} {name}:\")\n",
        "        print(f\"      Original: {orig_count:,} â†’ Cleaned: {clean_count:,}\")\n",
        "\n",
        "# ============================================================\n",
        "# 5. COMMON WORDS ANALYSIS\n",
        "# ============================================================\n",
        "print(f\"\\n 5. MOST COMMON WORDS (Top 20)\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "def get_word_freq(text_series, top_n=20):\n",
        "    words = []\n",
        "    for text in text_series:\n",
        "        words.extend(str(text).split())\n",
        "    return Counter(words).most_common(top_n)\n",
        "\n",
        "common_words = get_word_freq(df[cleaned_col], 20)\n",
        "print(\"\\nTop 20 words:\")\n",
        "for i, (word, count) in enumerate(common_words, 1):\n",
        "    print(f\"  {i:2d}. {word:15s} â†’ {count:5,} times\")\n",
        "\n",
        "# ============================================================\n",
        "# 6. SENTENCE SAMPLES\n",
        "# ============================================================\n",
        "print(f\"\\n 6. BEFORE/AFTER COMPARISON (10 Random Samples)\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "sample_indices = df.sample(min(10, len(df)), random_state=42).index\n",
        "\n",
        "for i, idx in enumerate(sample_indices, 1):\n",
        "    orig = df.loc[idx, original_col]\n",
        "    clean = df.loc[idx, cleaned_col]\n",
        "\n",
        "    print(f\"\\nSample {i}:\")\n",
        "    print(f\"  ORIGINAL: {orig}\")\n",
        "    print(f\"  CLEANED:  {clean}\")\n",
        "\n",
        "    if orig != clean:\n",
        "        print(f\"  LENGTH:   {len(orig)} â†’ {len(clean)} chars\")\n",
        "        removed = set(orig) - set(clean)\n",
        "        if removed:\n",
        "            print(f\"  REMOVED:  {sorted(removed)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. VISUALIZATION (FIXED)\n",
        "# ============================================================\n",
        "print(f\"\\n 7. GENERATING VISUALIZATIONS...\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Length distribution\n",
        "axes[0, 0].hist(orig_lengths, bins=50, alpha=0.7, label='Original', color='blue')\n",
        "axes[0, 0].hist(clean_lengths, bins=50, alpha=0.7, label='Cleaned', color='green')\n",
        "axes[0, 0].set_xlabel('Text Length (characters)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Text Length Distribution')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Character count (FIXED)\n",
        "char_types = ['Urdu\\nChars', 'Digits', 'Punct', 'Latin', 'Other']\n",
        "orig_counts = [\n",
        "    len(orig_urdu.union(orig_arabic)),  # FIXED: Use returned variables\n",
        "    len(orig_digits),\n",
        "    len(orig_punct),\n",
        "    len(orig_latin),\n",
        "    len(orig_other)\n",
        "]\n",
        "\n",
        "axes[0, 1].bar(char_types, orig_counts, color=['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#95a5a6'])\n",
        "axes[0, 1].set_ylabel('Unique Character Count')\n",
        "axes[0, 1].set_title('Character Type Distribution (Original)')\n",
        "axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 3: Top 15 words\n",
        "words, counts = zip(*common_words[:15])\n",
        "axes[1, 0].barh(range(len(words)), counts, color='#3498db')\n",
        "axes[1, 0].set_yticks(range(len(words)))\n",
        "axes[1, 0].set_yticklabels(words, fontsize=10)\n",
        "axes[1, 0].set_xlabel('Frequency')\n",
        "axes[1, 0].set_title('Top 15 Most Common Words (Cleaned)')\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "axes[1, 0].invert_yaxis()\n",
        "\n",
        "# Plot 4: Word count distribution\n",
        "word_counts = df[cleaned_col].str.split().str.len()\n",
        "axes[1, 1].hist(word_counts, bins=30, color='#2ecc71', edgecolor='black')\n",
        "axes[1, 1].set_xlabel('Words per Sentence')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Sentence Length Distribution (Word Count)')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/preprocessing_analysis.png', dpi=150, bbox_inches='tight')\n",
        "print(\" Visualization saved: /content/preprocessing_analysis.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 8. QUALITY SCORE\n",
        "# ============================================================\n",
        "print(f\"\\n 8. PREPROCESSING QUALITY SCORE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "score = 0\n",
        "max_score = 7\n",
        "\n",
        "# Check 1: Diacritics removed\n",
        "if clean_with_diacritics == 0:\n",
        "    score += 1\n",
        "    print(\" [1/1] Diacritics completely removed\")\n",
        "else:\n",
        "    print(f\" [0/1] {clean_with_diacritics} sentences still have diacritics\")\n",
        "\n",
        "# Check 2: Normalization applied\n",
        "normalization_checks = sum(1 for pattern in checks.values()\n",
        "                           if df[cleaned_col].str.contains(pattern, regex=True).sum() == 0)\n",
        "score += min(2, normalization_checks / len(checks) * 2)\n",
        "print(f\"{'' if normalization_checks >= 7 else ''} [{min(2, normalization_checks / len(checks) * 2):.1f}/2] Character normalization: {normalization_checks}/{len(checks)} passed\")\n",
        "\n",
        "# Check 3: No empty sentences\n",
        "empty_count = (df[cleaned_col].str.len() == 0).sum()\n",
        "if empty_count == 0:\n",
        "    score += 1\n",
        "    print(\" [1/1] No empty sentences\")\n",
        "else:\n",
        "    print(f\" [0/1] {empty_count} empty sentences found\")\n",
        "\n",
        "# Check 4: Reasonable length reduction\n",
        "avg_reduction = orig_lengths.mean() - clean_lengths.mean()\n",
        "if 0 <= avg_reduction <= orig_lengths.mean() * 0.3:\n",
        "    score += 1\n",
        "    print(f\" [1/1] Length reduction reasonable ({avg_reduction:.1f} chars)\")\n",
        "else:\n",
        "    print(f\" [0/1] Length reduction too high ({avg_reduction:.1f} chars)\")\n",
        "\n",
        "# Check 5: Urdu characters preserved\n",
        "if len(clean_urdu) >= len(orig_urdu) * 0.9:\n",
        "    score += 1\n",
        "    print(\" [1/1] Urdu characters preserved\")\n",
        "else:\n",
        "    print(\" [0/1] Significant Urdu character loss detected\")\n",
        "\n",
        "# Check 6: Consistent encoding\n",
        "try:\n",
        "    df[cleaned_col].str.encode('utf-8')\n",
        "    score += 1\n",
        "    print(\" [1/1] UTF-8 encoding consistent\")\n",
        "except:\n",
        "    print(\" [0/1] Encoding issues detected\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\" FINAL QUALITY SCORE: {score:.1f}/{max_score} ({100*score/max_score:.1f}%)\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if score >= 6:\n",
        "    print(\" EXCELLENT: Preprocessing is working perfectly!\")\n",
        "elif score >= 4:\n",
        "    print(\" GOOD: Minor issues detected, but acceptable for training\")\n",
        "else:\n",
        "    print(\" POOR: Significant preprocessing issues found. Review normalization rules.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w8e6O4T0bUqb",
        "outputId": "1245e3f4-84b4-4a86-b752-bd9585179754"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            " PREPROCESSING QUALITY VERIFICATION\n",
            "================================================================================\n",
            "\n",
            " 1. BASIC STATISTICS\n",
            "--------------------------------------------------------------------------------\n",
            "Total sentences: 20,000\n",
            "Columns: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accents', 'variant', 'locale', 'segment', 'clean_text']\n",
            "\n",
            " Text Length Statistics:\n",
            "  Original - Min: 2, Max: 9670, Mean: 36.2\n",
            "  Cleaned  - Min: 2, Max: 9406, Mean: 36.1\n",
            "  Avg reduction: 0.1 characters\n",
            "\n",
            "ğŸ”¤ 2. CHARACTER SET ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ORIGINAL TEXT:\n",
            "  Unique characters: 124\n",
            "  Urdu/Arabic chars: 67\n",
            "  Digits: 10 â†’ ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "  Punctuation: 6 â†’ ['!', '\"', \"'\", ',', '.', ':']\n",
            "  Latin chars: 18 â†’ ['a', 'b', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v']\n",
            "  Other/Special: 20 â†’ ['-', '_', '`', 'â€˜', 'â€™', 'â€œ', 'â€', 'â€¦', 'ï­¨', 'ï®­', 'ï®¯', 'ï¯¾', 'ï·²', 'ï·º', 'ïº—', 'ïº˜', 'ïº©', 'ïº²', 'ï»§', 'ï»®']\n",
            "\n",
            "CLEANED TEXT:\n",
            "  Unique characters: 82\n",
            "  Urdu/Arabic chars: 44\n",
            "  Digits: 10 â†’ ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "  Punctuation: 8 â†’ ['!', '\"', \"'\", ',', '.', ':', ';', '?']\n",
            "  Latin chars: 18 â†’ ['a', 'b', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v']\n",
            "  Other/Special: 1 â†’ ['-']\n",
            "\n",
            " Removed characters (44): ['\\t', '\\n', '_', '`', 'ØŒ', 'Ø›', 'ØŸ', 'Ø¢', 'Ø£', 'Ø¤', 'Ø¦', 'Ùƒ', 'Ù‰', 'ÙŠ', 'Ù‹', 'Ù', 'Ù', 'Ù', 'Ù‘', 'Ù’', 'Ù“', 'Ù”', 'Ù—', 'Ù°', 'Ú¾', 'Ûƒ', 'Û”', 'â€˜', 'â€™', 'â€œ', 'â€', 'â€¦', 'ï­¨', 'ï®­', 'ï®¯', 'ï¯¾', 'ï·²', 'ï·º', 'ïº—', 'ïº˜', 'ïº©', 'ïº²', 'ï»§', 'ï»®']\n",
            "\n",
            " 3. DIACRITICS VERIFICATION\n",
            "--------------------------------------------------------------------------------\n",
            "Sentences with diacritics:\n",
            "  Original: 743 (3.7%)\n",
            "  Cleaned:  0 (0.0%)\n",
            "   All diacritics removed successfully!\n",
            "\n",
            " 4. NORMALIZATION VERIFICATION\n",
            "--------------------------------------------------------------------------------\n",
            "Checking for unnormalized characters:\n",
            "   Alef variants (Ø£Ø¥Ø¢Ù±):\n",
            "      Original: 2,620 â†’ Cleaned: 0\n",
            "   Yeh variants (ÙŠÙ‰Ø¦):\n",
            "      Original: 5,195 â†’ Cleaned: 0\n",
            "   Arabic Kaf (Ùƒ):\n",
            "      Original: 6 â†’ Cleaned: 0\n",
            "   Urdu comma (ØŒ):\n",
            "      Original: 536 â†’ Cleaned: 0\n",
            "   Urdu question (ØŸ):\n",
            "      Original: 782 â†’ Cleaned: 0\n",
            "\n",
            " 5. MOST COMMON WORDS (Top 20)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Top 20 words:\n",
            "   1. Ú©ÛŒ              â†’ 4,247 times\n",
            "   2. Ú©Û’              â†’ 4,173 times\n",
            "   3. Ù…ÛŒÚº             â†’ 4,162 times\n",
            "   4. Ú©Ø§              â†’ 3,223 times\n",
            "   5. ÛÛ’              â†’ 2,849 times\n",
            "   6. Ø³Û’              â†’ 2,787 times\n",
            "   7. ÛÛ’.             â†’ 2,669 times\n",
            "   8. Ú©Ùˆ              â†’ 2,068 times\n",
            "   9. Ø§ÙˆØ±             â†’ 1,894 times\n",
            "  10. Ø§Ø³              â†’ 1,863 times\n",
            "  11. ÛŒÛ              â†’ 1,645 times\n",
            "  12. Ù†ÛÛŒÚº            â†’ 1,456 times\n",
            "  13. ØªÙˆ              â†’ 1,379 times\n",
            "  14. Ù†Û’              â†’ 1,369 times\n",
            "  15. Ø¨ÛÛŒ             â†’ 1,327 times\n",
            "  16. Ù¾Ø±              â†’ 1,315 times\n",
            "  17. ÛÛŒÚº.            â†’ 1,211 times\n",
            "  18. ÛÛŒÚº             â†’ 1,169 times\n",
            "  19. Ø§ÛŒÚ©             â†’ 1,159 times\n",
            "  20. Ú©ÛŒØ§             â†’ 1,142 times\n",
            "\n",
            " 6. BEFORE/AFTER COMPARISON (10 Random Samples)\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Sample 1:\n",
            "  ORIGINAL: Ø§Ø³ Ù…ÛŒÚº Ø³Ø± ÙÛØ±Ø³Øª Ø¨Ø§Ø¯Ø´Ø§Û ÛÛŒÚºÛ”\n",
            "  CLEANED:  Ø§Ø³ Ù…ÛŒÚº Ø³Ø± ÙÛØ±Ø³Øª Ø¨Ø§Ø¯Ø´Ø§Û ÛÛŒÚº.\n",
            "  LENGTH:   27 â†’ 27 chars\n",
            "  REMOVED:  ['Û”']\n",
            "\n",
            "Sample 2:\n",
            "  ORIGINAL: ÙˆØ±Ù„Úˆ Ú©Ù¾ Ú©Ø±Ú©Ù¹ Ú©ÛŒ Ù¹Ø±Ø§ÙÛŒ Ú©Û’ Ø·ÙˆÛŒÙ„ ØªØ±ÛŒÙ† Ø³ÙØ± Ú©Ø§ Ø´ÛŒÚˆÙˆÙ„ Ø¬Ø§Ø±ÛŒ\n",
            "  CLEANED:  ÙˆØ±Ù„Úˆ Ú©Ù¾ Ú©Ø±Ú©Ù¹ Ú©ÛŒ Ù¹Ø±Ø§ÙÛŒ Ú©Û’ Ø·ÙˆÛŒÙ„ ØªØ±ÛŒÙ† Ø³ÙØ± Ú©Ø§ Ø´ÛŒÚˆÙˆÙ„ Ø¬Ø§Ø±ÛŒ\n",
            "\n",
            "Sample 3:\n",
            "  ORIGINAL: Ø³ÛŒØ§Ø³ÛŒ Ù…ÛŒØ¯Ø§Ù† Ù…ÛŒÚº Ø¬Ùˆ Ø¯ÙˆØ³Ø±ÛŒ Ù‚ÙˆØª ØªÚ¾ÛŒÛ”\n",
            "  CLEANED:  Ø³ÛŒØ§Ø³ÛŒ Ù…ÛŒØ¯Ø§Ù† Ù…ÛŒÚº Ø¬Ùˆ Ø¯ÙˆØ³Ø±ÛŒ Ù‚ÙˆØª ØªÛÛŒ.\n",
            "  LENGTH:   33 â†’ 33 chars\n",
            "  REMOVED:  ['Ú¾', 'Û”']\n",
            "\n",
            "Sample 4:\n",
            "  ORIGINAL: ÛÙ¹Ù„Ø± Ø§Ø³ Ú©Ø§ Ø®Ø§Øµ Ø§ÛØªÙ…Ø§Ù… Ú©Ø±ØªØ§ ØªÚ¾Ø§Û”\n",
            "  CLEANED:  ÛÙ¹Ù„Ø± Ø§Ø³ Ú©Ø§ Ø®Ø§Øµ Ø§ÛØªÙ…Ø§Ù… Ú©Ø±ØªØ§ ØªÛØ§.\n",
            "  LENGTH:   31 â†’ 31 chars\n",
            "  REMOVED:  ['Ú¾', 'Û”']\n",
            "\n",
            "Sample 5:\n",
            "  ORIGINAL: Ù…Ø§Ø¶ÛŒ Ú©ÛŒ ØºÙ„Ø·ÛŒØ§Úº Ù…Ø³ØªÙ‚Ø¨Ù„ Ú©Û’ Ù„ÛŒÛ’ Ø±Ø§ÛÙ†Ù…Ø§ Ø¨Ù† Ø±ÛÛŒ ÛÛŒÚºÛ”\n",
            "  CLEANED:  Ù…Ø§Ø¶ÛŒ Ú©ÛŒ ØºÙ„Ø·ÛŒØ§Úº Ù…Ø³ØªÙ‚Ø¨Ù„ Ú©Û’ Ù„ÛŒÛ’ Ø±Ø§ÛÙ†Ù…Ø§ Ø¨Ù† Ø±ÛÛŒ ÛÛŒÚº.\n",
            "  LENGTH:   47 â†’ 47 chars\n",
            "  REMOVED:  ['Û”']\n",
            "\n",
            "Sample 6:\n",
            "  ORIGINAL: Ø¢Ø³Ø§Ù†ÛŒ Ø³Û’ Ø¯Ø¨Ø§Ùˆ Ù…ÛŒÚº Ø¢ Ø¬Ø§ØªØ§ ÛÙˆÚº\n",
            "  CLEANED:  Ø§Ø³Ø§Ù†ÛŒ Ø³Û’ Ø¯Ø¨Ø§Ùˆ Ù…ÛŒÚº Ø§ Ø¬Ø§ØªØ§ ÛÙˆÚº\n",
            "  LENGTH:   28 â†’ 28 chars\n",
            "  REMOVED:  ['Ø¢']\n",
            "\n",
            "Sample 7:\n",
            "  ORIGINAL: Ø¹Ø²ÛŒØ± Ø¬Ø³ÙˆØ§Ù„ Ù†Û’ Ø§Ø¯Ø§Ú©Ø§Ø±ÛŒ Ú©Û’ Ù…ÛŒØ¯Ø§Ù† Ù…ÛŒÚº Ù‚Ø¯Ù… Ø±Ú©Ú¾ Ù„ÛŒØ§\n",
            "  CLEANED:  Ø¹Ø²ÛŒØ± Ø¬Ø³ÙˆØ§Ù„ Ù†Û’ Ø§Ø¯Ø§Ú©Ø§Ø±ÛŒ Ú©Û’ Ù…ÛŒØ¯Ø§Ù† Ù…ÛŒÚº Ù‚Ø¯Ù… Ø±Ú©Û Ù„ÛŒØ§\n",
            "  LENGTH:   46 â†’ 46 chars\n",
            "  REMOVED:  ['Ú¾']\n",
            "\n",
            "Sample 8:\n",
            "  ORIGINAL: ØµØ­ØªØŒ ØªØ¹Ù„ÛŒÙ… Ø§ÙˆØ± Ø§Ù†ØµØ§Ù Ù‚ÙˆÙ… Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª ÛÛŒÚºÛ”\n",
            "  CLEANED:  ØµØ­Øª, ØªØ¹Ù„ÛŒÙ… Ø§ÙˆØ± Ø§Ù†ØµØ§Ù Ù‚ÙˆÙ… Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¶Ø±ÙˆØ±ÛŒØ§Øª ÛÛŒÚº.\n",
            "  LENGTH:   47 â†’ 47 chars\n",
            "  REMOVED:  ['ØŒ', 'Û”']\n",
            "\n",
            "Sample 9:\n",
            "  ORIGINAL: Ø¢Ø¬ Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª ÛÙˆÚºÛ”\n",
            "  CLEANED:  Ø§Ø¬ Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª ÛÙˆÚº.\n",
            "  LENGTH:   16 â†’ 16 chars\n",
            "  REMOVED:  ['Ø¢', 'Û”']\n",
            "\n",
            "Sample 10:\n",
            "  ORIGINAL: Ø¬ÛŒØ³Û’ Ù…Ú©Ú¾Ù† Ø³Û’ Ú†Ú¾Ø±ÛŒÛ”\n",
            "  CLEANED:  Ø¬ÛŒØ³Û’ Ù…Ú©ÛÙ† Ø³Û’ Ú†ÛØ±ÛŒ.\n",
            "  LENGTH:   18 â†’ 18 chars\n",
            "  REMOVED:  ['Ú¾', 'Û”']\n",
            "\n",
            " 7. GENERATING VISUALIZATIONS...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2024324966.py:219: UserWarning: Glyph 1746 (\\N{ARABIC LETTER YEH BARREE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2024324966.py:219: UserWarning: Matplotlib currently does not support Arabic natively.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2024324966.py:219: UserWarning: Glyph 1729 (\\N{ARABIC LETTER HEH GOAL}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2024324966.py:220: UserWarning: Glyph 1746 (\\N{ARABIC LETTER YEH BARREE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('/content/preprocessing_analysis.png', dpi=150, bbox_inches='tight')\n",
            "/tmp/ipython-input-2024324966.py:220: UserWarning: Matplotlib currently does not support Arabic natively.\n",
            "  plt.savefig('/content/preprocessing_analysis.png', dpi=150, bbox_inches='tight')\n",
            "/tmp/ipython-input-2024324966.py:220: UserWarning: Glyph 1729 (\\N{ARABIC LETTER HEH GOAL}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('/content/preprocessing_analysis.png', dpi=150, bbox_inches='tight')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Visualization saved: /content/preprocessing_analysis.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 1746 (\\N{ARABIC LETTER YEH BARREE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Matplotlib currently does not support Arabic natively.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 1729 (\\N{ARABIC LETTER HEH GOAL}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 8. PREPROCESSING QUALITY SCORE\n",
            "================================================================================\n",
            " [1/1] Diacritics completely removed\n",
            " [2.0/2] Character normalization: 9/9 passed\n",
            " [1/1] No empty sentences\n",
            " [1/1] Length reduction reasonable (0.1 chars)\n",
            " [0/1] Significant Urdu character loss detected\n",
            " [1/1] UTF-8 encoding consistent\n",
            "\n",
            "================================================================================\n",
            " FINAL QUALITY SCORE: 6.0/7 (85.7%)\n",
            "================================================================================\n",
            " EXCELLENT: Preprocessing is working perfectly!\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 6 â€” Build Source â†’ Destination Pairs  \n",
        "\n",
        "**Purpose:**  \n",
        "Since dataset has single-column transcripts,  \n",
        "we create conversation pairs automatically using the **previous-line rule**:  \n",
        "\n"
      ],
      "metadata": {
        "id": "yc6eprfjKIY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Result:**  \n",
        "List of `(src, dst)` pairs used for sequence-to-sequence training.  \n"
      ],
      "metadata": {
        "id": "n_AK8sWXKKN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# SPAN CORRUPTION DATA STRATEGY (T5-Style)\n",
        "# ========================================\n",
        "\n",
        "import random\n",
        "import re\n",
        "\n",
        "utterances = df[text_col].astype(str).tolist()\n",
        "\n",
        "# Filter quality sentences\n",
        "quality_sentences = [\n",
        "    s for s in utterances\n",
        "    if 8 <= len(s.split()) <= 40  # Good length for corruption\n",
        "    and len(s) >= 30  # Min characters\n",
        "    and s.strip()\n",
        "]\n",
        "\n",
        "print(f\"Quality sentences: {len(quality_sentences):,} / {len(utterances):,}\")\n",
        "\n",
        "pairs = []\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY 1: SPAN CORRUPTION (Primary Strategy)\n",
        "# ============================================================\n",
        "print(\"\\n Strategy 1: Span Corruption (T5-Style)...\")\n",
        "\n",
        "def create_span_corruption(sentence, noise_density=0.15, mean_span_length=3):\n",
        "    \"\"\"\n",
        "    Create span corruption pairs like T5.\n",
        "\n",
        "    Args:\n",
        "        sentence: Original sentence\n",
        "        noise_density: Fraction of tokens to corrupt (0.15 = 15%)\n",
        "        mean_span_length: Average span length to mask\n",
        "\n",
        "    Returns:\n",
        "        (corrupted_input, target_spans)\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    n_words = len(words)\n",
        "\n",
        "    if n_words < 5:\n",
        "        return None, None\n",
        "\n",
        "    # Calculate number of tokens to corrupt\n",
        "    n_corrupt = max(1, int(n_words * noise_density))\n",
        "\n",
        "    # Generate span positions\n",
        "    spans_to_mask = []\n",
        "    remaining = n_corrupt\n",
        "\n",
        "    while remaining > 0:\n",
        "        # Random span length (exponential distribution around mean)\n",
        "        span_len = min(remaining, max(1, int(random.expovariate(1.0 / mean_span_length))))\n",
        "\n",
        "        # Random start position\n",
        "        max_start = n_words - span_len\n",
        "        if max_start < 0:\n",
        "            break\n",
        "\n",
        "        start = random.randint(0, max_start)\n",
        "        end = start + span_len\n",
        "\n",
        "        # Check for overlap with existing spans\n",
        "        overlap = False\n",
        "        for existing_start, existing_end, _ in spans_to_mask:\n",
        "            if not (end <= existing_start or start >= existing_end):\n",
        "                overlap = True\n",
        "                break\n",
        "\n",
        "        if not overlap:\n",
        "            spans_to_mask.append((start, end, len(spans_to_mask)))\n",
        "            remaining -= span_len\n",
        "\n",
        "    if not spans_to_mask:\n",
        "        return None, None\n",
        "\n",
        "    # Sort spans by position\n",
        "    spans_to_mask.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Build corrupted input and target\n",
        "    corrupted_words = []\n",
        "    target_words = []\n",
        "    last_pos = 0\n",
        "\n",
        "    for start, end, span_id in spans_to_mask:\n",
        "        # Add words before span\n",
        "        corrupted_words.extend(words[last_pos:start])\n",
        "\n",
        "        # Add mask token\n",
        "        corrupted_words.append(f\"[MASK{span_id}]\")\n",
        "\n",
        "        # Add masked words to target\n",
        "        target_words.append(f\"[SPAN{span_id}]\")\n",
        "        target_words.extend(words[start:end])\n",
        "\n",
        "        last_pos = end\n",
        "\n",
        "    # Add remaining words\n",
        "    corrupted_words.extend(words[last_pos:])\n",
        "\n",
        "    corrupted_input = ' '.join(corrupted_words)\n",
        "    target_output = ' '.join(target_words)\n",
        "\n",
        "    return corrupted_input, target_output\n",
        "\n",
        "\n",
        "# Generate span corruption pairs\n",
        "strategy1_pairs = []\n",
        "\n",
        "for sent in quality_sentences:\n",
        "    # Create multiple corruptions of same sentence (different noise patterns)\n",
        "    for noise_level in [0.15, 0.25, 0.35]:  # 15%, 25%, 35% corruption\n",
        "        corrupted, target = create_span_corruption(sent, noise_density=noise_level)\n",
        "\n",
        "        if corrupted and target and len(target.split()) >= 3:\n",
        "            strategy1_pairs.append((corrupted, target))\n",
        "\n",
        "pairs.extend(strategy1_pairs)\n",
        "print(f\"   Generated {len(strategy1_pairs):,} span corruption pairs\")\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY 2: SENTENCE PERMUTATION (Order Reconstruction)\n",
        "# ============================================================\n",
        "print(\"\\n Strategy 2: Sentence permutation...\")\n",
        "\n",
        "strategy2_pairs = []\n",
        "\n",
        "for sent in quality_sentences:\n",
        "    words = sent.split()\n",
        "    if len(words) < 8:\n",
        "        continue\n",
        "\n",
        "    # Shuffle words (keep first and last)\n",
        "    middle = words[1:-1]\n",
        "    shuffled_middle = random.sample(middle, len(middle))\n",
        "    shuffled = [words[0]] + shuffled_middle + [words[-1]]\n",
        "\n",
        "    shuffled_text = ' '.join(shuffled)\n",
        "    original_text = sent\n",
        "\n",
        "    strategy2_pairs.append((shuffled_text, original_text))\n",
        "\n",
        "pairs.extend(strategy2_pairs)\n",
        "print(f\"   Generated {len(strategy2_pairs):,} permutation pairs\")\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY 3: TOKEN REPLACEMENT (Denoising)\n",
        "# ============================================================\n",
        "print(\"\\n Strategy 3: Token replacement...\")\n",
        "\n",
        "strategy3_pairs = []\n",
        "\n",
        "# Common Urdu words for replacement noise\n",
        "noise_tokens = [\"[NOISE]\", \"###\", \"???\", \"***\"]\n",
        "\n",
        "for sent in quality_sentences[:10000]:\n",
        "    words = sent.split()\n",
        "    if len(words) < 6:\n",
        "        continue\n",
        "\n",
        "    # Replace 10-20% of words with noise\n",
        "    n_replace = max(1, int(len(words) * 0.15))\n",
        "    positions = random.sample(range(len(words)), n_replace)\n",
        "\n",
        "    noisy_words = words.copy()\n",
        "    replaced_words = []\n",
        "\n",
        "    for pos in positions:\n",
        "        original_word = noisy_words[pos]\n",
        "        noisy_words[pos] = random.choice(noise_tokens)\n",
        "        replaced_words.append(f\"[POS{pos}] {original_word}\")\n",
        "\n",
        "    noisy_text = ' '.join(noisy_words)\n",
        "    clean_text = ' '.join(replaced_words)\n",
        "\n",
        "    strategy3_pairs.append((noisy_text, clean_text))\n",
        "\n",
        "pairs.extend(strategy3_pairs)\n",
        "print(f\"   Generated {len(strategy3_pairs):,} denoising pairs\")\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY 4: PREFIX COMPLETION (Sentence Continuation)\n",
        "# ============================================================\n",
        "print(\"\\n Strategy 4: Prefix completion...\")\n",
        "\n",
        "strategy4_pairs = []\n",
        "\n",
        "for sent in quality_sentences:\n",
        "    words = sent.split()\n",
        "    if len(words) < 10:\n",
        "        continue\n",
        "\n",
        "    # Create prefix-completion pairs at different split points\n",
        "    for split_ratio in [0.3, 0.5, 0.7]:\n",
        "        split_point = int(len(words) * split_ratio)\n",
        "\n",
        "        prefix = ' '.join(words[:split_point])\n",
        "        completion = ' '.join(words[split_point:])\n",
        "\n",
        "        if len(prefix.split()) >= 3 and len(completion.split()) >= 3:\n",
        "            strategy4_pairs.append((prefix + \" [CONTINUE]\", completion))\n",
        "\n",
        "pairs.extend(strategy4_pairs)\n",
        "print(f\"   Generated {len(strategy4_pairs):,} completion pairs\")\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY 5: Multi-Turn Context (Keep from before)\n",
        "# ============================================================\n",
        "print(\"\\n Strategy 5: Multi-turn context...\")\n",
        "strategy5_pairs = []\n",
        "\n",
        "if 'client_id' in df.columns:\n",
        "    grouped = df.groupby('client_id')[text_col].apply(list)\n",
        "\n",
        "    for speaker_sentences in grouped:\n",
        "        if len(speaker_sentences) < 3:\n",
        "            continue\n",
        "\n",
        "        for i in range(2, len(speaker_sentences)):\n",
        "            context = f\"{speaker_sentences[i-2]} [SEP] {speaker_sentences[i-1]}\"\n",
        "            target = speaker_sentences[i]\n",
        "\n",
        "            if (10 <= len(context.split()) <= 80 and\n",
        "                5 <= len(target.split()) <= 30):\n",
        "                strategy5_pairs.append((context, target))\n",
        "\n",
        "pairs.extend(strategy5_pairs)\n",
        "print(f\"   Generated {len(strategy5_pairs):,} context pairs\")\n",
        "\n",
        "# ============================================================\n",
        "# FINAL PROCESSING\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\" TOTAL PAIRS GENERATED: {len(pairs):,}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Remove duplicates\n",
        "pairs = list(set(pairs))\n",
        "print(f\"After removing duplicates: {len(pairs):,}\")\n",
        "\n",
        "# Shuffle\n",
        "random.shuffle(pairs)\n",
        "\n",
        "# Quality check\n",
        "print(\"\\n SAMPLE PAIRS FROM EACH STRATEGY:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1ï¸âƒ£ Span Corruption (T5-Style):\")\n",
        "for i in range(min(3, len(strategy1_pairs))):\n",
        "    print(f\"   Input:  {strategy1_pairs[i][0]}\")\n",
        "    print(f\"   Target: {strategy1_pairs[i][1]}\\n\")\n",
        "\n",
        "print(\"\\n2ï¸âƒ£ Sentence Permutation:\")\n",
        "for i in range(min(3, len(strategy2_pairs))):\n",
        "    print(f\"   Input:  {strategy2_pairs[i][0]}\")\n",
        "    print(f\"   Target: {strategy2_pairs[i][1]}\\n\")\n",
        "\n",
        "print(\"\\n3ï¸âƒ£ Token Replacement:\")\n",
        "for i in range(min(3, len(strategy3_pairs))):\n",
        "    print(f\"   Input:  {strategy3_pairs[i][0]}\")\n",
        "    print(f\"   Target: {strategy3_pairs[i][1]}\\n\")\n",
        "\n",
        "print(\"\\n4ï¸âƒ£ Prefix Completion:\")\n",
        "for i in range(min(3, len(strategy4_pairs))):\n",
        "    print(f\"   Input:  {strategy4_pairs[i][0]}\")\n",
        "    print(f\"   Target: {strategy4_pairs[i][1]}\\n\")\n",
        "\n",
        "# Split data\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" CREATING TRAIN/VAL/TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "input_texts, target_texts = zip(*pairs)\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    input_texts, target_texts,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n Split complete:\")\n",
        "print(f\"   Train: {len(X_train):,} pairs\")\n",
        "print(f\"   Val:   {len(X_val):,} pairs\")\n",
        "print(f\"   Test:  {len(X_test):,} pairs\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbAPS5VkLPJc",
        "outputId": "aa252297-72a3-438d-e0e5-4a327742cabf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality sentences: 9,680 / 20,000\n",
            "\n",
            " Strategy 1: Span Corruption (T5-Style)...\n",
            "   Generated 20,787 span corruption pairs\n",
            "\n",
            " Strategy 2: Sentence permutation...\n",
            "   Generated 9,680 permutation pairs\n",
            "\n",
            " Strategy 3: Token replacement...\n",
            "   Generated 9,680 denoising pairs\n",
            "\n",
            " Strategy 4: Prefix completion...\n",
            "   Generated 19,179 completion pairs\n",
            "\n",
            " Strategy 5: Multi-turn context...\n",
            "   Generated 15,021 context pairs\n",
            "\n",
            "================================================================================\n",
            " TOTAL PAIRS GENERATED: 74,347\n",
            "================================================================================\n",
            "After removing duplicates: 63,211\n",
            "\n",
            " SAMPLE PAIRS FROM EACH STRATEGY:\n",
            "================================================================================\n",
            "\n",
            "1ï¸âƒ£ Span Corruption (T5-Style):\n",
            "   Input:  Ø§ÙˆØ± [MASK0] ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛÛŒ ÛÙˆ\n",
            "   Target: [SPAN0] Ù¾ÛØ± Ù…Ù…Ú©Ù†\n",
            "\n",
            "   Input:  [MASK1] [MASK0] Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛÛŒ ÛÙˆ\n",
            "   Target: [SPAN1] Ø§ÙˆØ± [SPAN0] Ù¾ÛØ±\n",
            "\n",
            "   Input:  [MASK0] Ú©Û’ Ø¨Ù„Û’ Ø¨Ø§Ø²ÙˆÚº Ú©Û’ Ø³Ø§Ù…Ù†Û’ [MASK1] Ú¯Ø§\n",
            "   Target: [SPAN0] Ø§Ù† [SPAN1] ÛÙˆ\n",
            "\n",
            "\n",
            "2ï¸âƒ£ Sentence Permutation:\n",
            "   Input:  Ø§ÙˆØ± Ú©Û Ø¨ÛÛŒ Ù¾ÛØ± Ù…Ù…Ú©Ù† Ù¾Ø§Ú©Ø³ØªØ§Ù† ÛÛ’ ÛÙˆ\n",
            "   Target: Ø§ÙˆØ± Ù¾ÛØ± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨ÛÛŒ ÛÙˆ\n",
            "\n",
            "   Input:  Ø§Ù† ÛÙˆ Ú©Û’ Ø¨Ø§Ø²ÙˆÚº Ø¨Ù„Û’ Ú©Û’ Ø³Ø§Ù…Ù†Û’ Ú¯Ø§\n",
            "   Target: Ø§Ù† Ú©Û’ Ø¨Ù„Û’ Ø¨Ø§Ø²ÙˆÚº Ú©Û’ Ø³Ø§Ù…Ù†Û’ ÛÙˆ Ú¯Ø§\n",
            "\n",
            "   Input:  Ø§Ø¨ÛŒ Ø¯ÙˆØ³Ø±Ø§ Ù¾Ø±Ù†Ø¯Û Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø§Ø¨ÛŒ Ø´Ø§Ù…Ù„ Ù…ÛŒÚº Ø¬Ø§Ù†ÙˆØ± ÛÙˆÙ†Ø§\n",
            "   Target: Ø§Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ Ø§Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´Ø§Ù…Ù„ ÛÙˆÙ†Ø§\n",
            "\n",
            "\n",
            "3ï¸âƒ£ Token Replacement:\n",
            "   Input:  Ø§ÙˆØ± Ù¾ÛØ± Ù…Ù…Ú©Ù† ÛÛ’ Ú©Û Ù¾Ø§Ú©Ø³ØªØ§Ù† ### ÛÙˆ\n",
            "   Target: [POS6] Ø¨ÛÛŒ\n",
            "\n",
            "   Input:  Ø§Ù† ??? Ø¨Ù„Û’ Ø¨Ø§Ø²ÙˆÚº Ú©Û’ Ø³Ø§Ù…Ù†Û’ ÛÙˆ Ú¯Ø§\n",
            "   Target: [POS1] Ú©Û’\n",
            "\n",
            "   Input:  Ø§Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº ??? Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ Ø§Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´Ø§Ù…Ù„ ÛÙˆÙ†Ø§\n",
            "   Target: [POS3] Ø¨Ø·Ø®\n",
            "\n",
            "\n",
            "4ï¸âƒ£ Prefix Completion:\n",
            "   Input:  Ø§Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº [CONTINUE]\n",
            "   Target: Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ Ø§Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´Ø§Ù…Ù„ ÛÙˆÙ†Ø§\n",
            "\n",
            "   Input:  Ø§Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ [CONTINUE]\n",
            "   Target: Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ Ø§Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´Ø§Ù…Ù„ ÛÙˆÙ†Ø§\n",
            "\n",
            "   Input:  Ø§Ø¨ÛŒ Ø¬Ø§Ù†ÙˆØ± Ù…ÛŒÚº Ø¨Ø·Ø® Ø¨Ú¯Ù„Ø§ Ø§ÙˆØ± Ø¯ÙˆØ³Ø±Ø§ [CONTINUE]\n",
            "   Target: Ø§Ø¨ÛŒ Ù¾Ø±Ù†Ø¯Û Ø´Ø§Ù…Ù„ ÛÙˆÙ†Ø§\n",
            "\n",
            "\n",
            "================================================================================\n",
            " CREATING TRAIN/VAL/TEST SPLIT\n",
            "================================================================================\n",
            "\n",
            " Split complete:\n",
            "   Train: 50,568 pairs\n",
            "   Val:   6,321 pairs\n",
            "   Test:  6,322 pairs\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¤ Cell 7 â€” Train SentencePiece (BPE Tokenizer)  \n",
        "\n",
        "**Purpose:**  \n",
        "Train a subword tokenizer that splits Urdu words into meaningful units (BPE).  \n",
        "SentencePiece generates a vocabulary of frequent subword pieces and assigns each an integer ID.  \n",
        "\n",
        "**Important:**  \n",
        "- BPE builds vocabulary only;  \n",
        "- Actual embeddings are learned later by the model (`nn.Embedding`).  \n"
      ],
      "metadata": {
        "id": "mOfgfEneKPGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spm_dir = \"/content/spm\"\n",
        "Path(spm_dir).mkdir(parents=True, exist_ok=True)\n",
        "spm_corpus = \"/content/spm_corpus.txt\"\n",
        "\n",
        "print(\" Writing new corpus for tokenizer training...\")\n",
        "\n",
        "# Write ALL data (train + val + test)\n",
        "with open(spm_corpus, \"w\", encoding=\"utf-8\") as f:\n",
        "    for a, b in zip(X_train, y_train):\n",
        "        f.write(a + \"\\n\")\n",
        "        f.write(b + \"\\n\")\n",
        "    for a, b in zip(X_val, y_val):\n",
        "        f.write(a + \"\\n\")\n",
        "        f.write(b + \"\\n\")\n",
        "    for a, b in zip(X_test, y_test):\n",
        "        f.write(a + \"\\n\")\n",
        "        f.write(b + \"\\n\")\n",
        "\n",
        "vocab_size = 20000\n",
        "\n",
        "print(f\"\\n Training SentencePiece tokenizer...\")\n",
        "print(f\"   Vocabulary size: {vocab_size:,}\")\n",
        "print(f\"   Special tokens: [PAD]=0, [BOS]=1, [EOS]=2, [UNK]=3\")\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input=spm_corpus,\n",
        "    model_prefix=os.path.join(spm_dir, \"urdu\"),\n",
        "    vocab_size=vocab_size,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=0.9995,\n",
        "    pad_id=0,\n",
        "    bos_id=1,\n",
        "    eos_id=2,\n",
        "    unk_id=3,\n",
        "    control_symbols=\"[SEP]\",\n",
        "    max_sentence_length=16384\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(os.path.join(spm_dir, \"urdu.model\"))\n",
        "\n",
        "PAD, BOS, EOS, UNK = 0, 1, 2, 3\n",
        "\n",
        "print(f\"\\n Tokenizer trained successfully!\")\n",
        "print(f\"   Vocabulary size: {sp.get_piece_size():,}\")\n",
        "print(f\"\\n Special Token Mapping:\")\n",
        "print(f\"   [PAD] = {PAD} â†’ '{sp.id_to_piece(PAD)}'\")\n",
        "print(f\"   [BOS] = {BOS} â†’ '{sp.id_to_piece(BOS)}'\")\n",
        "print(f\"   [EOS] = {EOS} â†’ '{sp.id_to_piece(EOS)}'\")\n",
        "print(f\"   [UNK] = {UNK} â†’ '{sp.id_to_piece(UNK)}'\")\n",
        "\n",
        "# Test tokenization\n",
        "test_pairs = [\n",
        "    (X_train[0], y_train[0]),\n",
        "    (X_train[100], y_train[100]),\n",
        "    (X_train[500], y_train[500])\n",
        "]\n",
        "\n",
        "print(f\"\\n Tokenization Test:\")\n",
        "print(\"=\"*80)\n",
        "for i, (src, tgt) in enumerate(test_pairs, 1):\n",
        "    src_ids = sp.encode(src, out_type=int)\n",
        "    tgt_ids = sp.encode(tgt, out_type=int)\n",
        "    print(f\"\\n{i}. Source: {src}\")\n",
        "    print(f\"   Tokens: {len(src_ids)} â†’ {src_ids[:10]}...\")\n",
        "    print(f\"   Target: {tgt}\")\n",
        "    print(f\"   Tokens: {len(tgt_ids)} â†’ {tgt_ids[:10]}...\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOQoOmEYLTvr",
        "outputId": "3de51740-224c-437b-f938-72c9fe410997"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Writing new corpus for tokenizer training...\n",
            "\n",
            " Training SentencePiece tokenizer...\n",
            "   Vocabulary size: 20,000\n",
            "   Special tokens: [PAD]=0, [BOS]=1, [EOS]=2, [UNK]=3\n",
            "\n",
            " Tokenizer trained successfully!\n",
            "   Vocabulary size: 20,000\n",
            "\n",
            " Special Token Mapping:\n",
            "   [PAD] = 0 â†’ '<pad>'\n",
            "   [BOS] = 1 â†’ '<s>'\n",
            "   [EOS] = 2 â†’ '</s>'\n",
            "   [UNK] = 3 â†’ '<unk>'\n",
            "\n",
            " Tokenization Test:\n",
            "================================================================================\n",
            "\n",
            "1. Source: ### Ø³Û’ Ø¯ÙˆØ± ÛÙˆÙ†Û’ Ú©Û’ Ø¨Ø§Ø¹Ø« ÛŒÛØ§Úº Ú¯Ø§Ú‘ÛŒÙˆÚº Ú©ÛŒ Ø§Ù…Ø¯ÙˆØ±ÙØª Ø¨ÛØª ??? ÛÙˆØªÛŒ ÛÛ’ .\n",
            "   Tokens: 15 â†’ [193, 45, 319, 313, 30, 997, 393, 1360, 13, 5889]...\n",
            "   Target: [POS0] Ø´ÛØ± [POS11] Ú©Ù…\n",
            "   Tokens: 8 â†’ [7, 70, 15, 1018, 7, 70, 1135, 204]...\n",
            "\n",
            "2. Source: Ù…Ø­ÙÙ„ ÛÙˆÛŒÛŒ Ø§Ù¾Ù†Û’ Ø®ØªÙ… Ø§Ù¾ ØªÙˆ Ú¯ÛØ± Ú¯ÛŒÛ’.\n",
            "   Tokens: 9 â†’ [4482, 482, 213, 624, 91, 88, 526, 315, 19964]...\n",
            "   Target: Ù…Ø­ÙÙ„ Ø®ØªÙ… ÛÙˆÛŒÛŒ ØªÙˆ Ø§Ù¾ Ø§Ù¾Ù†Û’ Ú¯ÛØ± Ú¯ÛŒÛ’.\n",
            "   Tokens: 9 â†’ [4482, 624, 482, 88, 91, 213, 526, 315, 19964]...\n",
            "\n",
            "3. Source: Ù…Ø§ÛØ± Ø§Ø±Ø¶ÛŒØ§Øª Ø³ÙˆØ±Ùˆ Ø³ÙˆØ±ÙˆÙ†Ùˆ Ø§Ù†ÚˆÙˆÙ†ÛŒØ´ÛŒØ§ Ú©ÛŒ Ø§Ø³ Ø§Ø¯Ø§Ø±ÛŒ Ú©ÛŒ Ø³Ø±Ø¨Ø±Ø§Û ###\n",
            "   Tokens: 11 â†’ [1854, 4347, 6074, 6113, 3707, 13, 41, 4332, 13, 2068]...\n",
            "   Target: [POS10] ÛÛŒÚº\n",
            "   Tokens: 4 â†’ [7, 70, 849, 56]...\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§© Cell 8 â€” Dataset Class, Collate Function, and Attention Masks  \n",
        "\n",
        "**Purpose:**  \n",
        "Convert text pairs into padded numerical tensors.  \n",
        "Creates necessary masks for the Transformer:  \n",
        "- **Encoder padding mask** â†’ ignores PAD tokens.  \n",
        "- **Decoder padding mask** â†’ hides PAD positions in decoder input.  \n",
        "- **Causal mask** â†’ prevents decoder from seeing future tokens.  \n",
        "\n",
        "**Why:**  \n",
        "These masks maintain correct token dependencies during training.  \n"
      ],
      "metadata": {
        "id": "D5Hm6lq_KRl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "MAX_LEN = 96\n",
        "BATCH = 64\n",
        "\n",
        "class PairDS(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that properly formats sequences for Transformer training.\n",
        "\n",
        "    Format:\n",
        "        Input (X):  [BOS] + tokens + [EOS] + [PAD]...\n",
        "        Target In:  [BOS] + tokens + [EOS] + [PAD]...\n",
        "        Target Out:        tokens + [EOS] + [PAD]... (shifted by 1)\n",
        "    \"\"\"\n",
        "    def __init__(self, xs, ys, sp, max_len=MAX_LEN):\n",
        "        self.xs = list(xs)\n",
        "        self.ys = list(ys)\n",
        "        self.sp = sp\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "    def encode_sequence(self, text, add_special=True):\n",
        "        \"\"\"\n",
        "        Encode text with proper special tokens.\n",
        "\n",
        "        Args:\n",
        "            text: Input text string\n",
        "            add_special: Whether to add [BOS] and [EOS] tokens\n",
        "\n",
        "        Returns:\n",
        "            Tensor of token IDs\n",
        "        \"\"\"\n",
        "        # Tokenize text\n",
        "        tokens = self.sp.encode(text, out_type=int)\n",
        "\n",
        "        # Truncate if too long (leave space for special tokens)\n",
        "        if len(tokens) > self.max_len - 2:\n",
        "            tokens = tokens[:self.max_len - 2]\n",
        "\n",
        "        if add_special:\n",
        "            # Add [BOS] at start and [EOS] at end\n",
        "            ids = [BOS] + tokens + [EOS]\n",
        "        else:\n",
        "            ids = tokens\n",
        "\n",
        "        return torch.tensor(ids, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            src: Source sequence with [BOS] + tokens + [EOS]\n",
        "            tgt: Target sequence with [BOS] + tokens + [EOS]\n",
        "        \"\"\"\n",
        "        src = self.encode_sequence(self.xs[idx], add_special=True)\n",
        "        tgt = self.encode_sequence(self.ys[idx], add_special=True)\n",
        "        return src, tgt\n",
        "\n",
        "\n",
        "def collate(batch):\n",
        "    \"\"\"\n",
        "    Collate function that properly handles padding and creates masks.\n",
        "\n",
        "    Creates:\n",
        "        - src_pad: Padded source sequences\n",
        "        - tgt_in: Target input (for decoder) = [BOS] + tokens\n",
        "        - tgt_out: Target output (for loss) = tokens + [EOS]\n",
        "        - src_kpm: Source key padding mask (True = pad)\n",
        "        - tgt_kpm: Target key padding mask (True = pad)\n",
        "        - causal: Causal mask (True = future position)\n",
        "    \"\"\"\n",
        "    srcs, tgts = zip(*batch)\n",
        "\n",
        "    S = max(len(s) for s in srcs)\n",
        "    T = max(len(t) for t in tgts)\n",
        "\n",
        "    src_pad = torch.full((len(batch), S), PAD, dtype=torch.long)\n",
        "    tgt_pad = torch.full((len(batch), T), PAD, dtype=torch.long)\n",
        "\n",
        "    for i, (s, t) in enumerate(zip(srcs, tgts)):\n",
        "        src_pad[i, :len(s)] = s\n",
        "        tgt_pad[i, :len(t)] = t\n",
        "\n",
        "    # Create decoder input/output\n",
        "    # tgt_in:  [BOS] token1 token2 ...\n",
        "    # tgt_out:       token1 token2 [EOS]\n",
        "    tgt_in = tgt_pad[:, :-1]  # Remove last token\n",
        "    tgt_out = tgt_pad[:, 1:]   # Remove first token ([BOS])\n",
        "\n",
        "    # Create padding masks (True = mask/ignore)\n",
        "    src_kpm = (src_pad == PAD)  # Shape: (batch, src_len)\n",
        "    tgt_kpm = (tgt_in == PAD)   # Shape: (batch, tgt_len-1)\n",
        "\n",
        "    # Create causal mask (prevent looking at future tokens)\n",
        "    Tm1 = tgt_in.size(1)\n",
        "    causal = torch.triu(torch.ones(Tm1, Tm1, dtype=torch.bool), diagonal=1)\n",
        "    # Shape: (tgt_len-1, tgt_len-1), True = block future\n",
        "\n",
        "    return src_pad, tgt_in, tgt_out, src_kpm, tgt_kpm, causal\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "train_dl = DataLoader(\n",
        "    PairDS(X_train, y_train, sp),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "valid_dl = DataLoader(\n",
        "    PairDS(X_val, y_val, sp),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "test_dl = DataLoader(\n",
        "    PairDS(X_test, y_test, sp),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate\n",
        ")\n",
        "\n",
        "print(\" Data loaders created successfully!\")\n",
        "print(f\"   Train batches: {len(train_dl)}\")\n",
        "print(f\"   Valid batches: {len(valid_dl)}\")\n",
        "print(f\"   Test batches:  {len(test_dl)}\")  #  Added\n",
        "\n",
        "\n",
        "print(\"\\n Verifying Data Format:\")\n",
        "sample_batch = next(iter(train_dl))\n",
        "src, tgt_in, tgt_out, src_kpm, tgt_kpm, causal = sample_batch\n",
        "\n",
        "print(f\"\\n Batch Shapes:\")\n",
        "print(f\"   Source (X):        {src.shape}\")\n",
        "print(f\"   Target Input:      {tgt_in.shape}\")\n",
        "print(f\"   Target Output:     {tgt_out.shape}\")\n",
        "print(f\"   Source Mask:       {src_kpm.shape}\")\n",
        "print(f\"   Target Mask:       {tgt_kpm.shape}\")\n",
        "print(f\"   Causal Mask:       {causal.shape}\")\n",
        "\n",
        "print(f\"\\n Sample Sequence (First in Batch):\")\n",
        "print(f\"   Source tokens:     {src[0][:10].tolist()}...\")\n",
        "print(f\"   Target in tokens:  {tgt_in[0][:10].tolist()}...\")\n",
        "print(f\"   Target out tokens: {tgt_out[0][:10].tolist()}...\")\n",
        "\n",
        "\n",
        "src_text = sp.decode([t for t in src[0].tolist() if t not in [PAD, BOS, EOS]])\n",
        "tgt_text = sp.decode([t for t in tgt_in[0].tolist() if t not in [PAD, BOS, EOS]])\n",
        "print(f\"\\n Decoded Sample:\")\n",
        "print(f\"   Source: {src_text}\")\n",
        "print(f\"   Target: {tgt_text}\")"
      ],
      "metadata": {
        "id": "L5adGAf-NkDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f4ebee-d248-4f62-98af-4b9216cd4400"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data loaders created successfully!\n",
            "   Train batches: 791\n",
            "   Valid batches: 99\n",
            "   Test batches:  99\n",
            "\n",
            " Verifying Data Format:\n",
            "\n",
            " Batch Shapes:\n",
            "   Source (X):        torch.Size([64, 34])\n",
            "   Target Input:      torch.Size([64, 27])\n",
            "   Target Output:     torch.Size([64, 27])\n",
            "   Source Mask:       torch.Size([64, 34])\n",
            "   Target Mask:       torch.Size([64, 27])\n",
            "   Causal Mask:       torch.Size([27, 27])\n",
            "\n",
            " Sample Sequence (First in Batch):\n",
            "   Source tokens:     [1, 1604, 2103, 313, 618, 67, 133, 397, 30, 5389]...\n",
            "   Target in tokens:  [1, 1604, 397, 30, 2103, 313, 67, 618, 133, 5389]...\n",
            "   Target out tokens: [1604, 397, 30, 2103, 313, 67, 618, 133, 5389, 3831]...\n",
            "\n",
            " Decoded Sample:\n",
            "   Source: Ø³Ù„Ù…Ø§Ù† Ø¨Ø±ÛŒ ÛÙˆÙ†Û’ Ø®ÙˆØ´ Ù¾Ø± ÛÙˆÚº Ø®Ø§Ù† Ú©Û’ Ø³Ù†Ø¬Û’ Ø¯Øª\n",
            "   Target: Ø³Ù„Ù…Ø§Ù† Ø®Ø§Ù† Ú©Û’ Ø¨Ø±ÛŒ ÛÙˆÙ†Û’ Ù¾Ø± Ø®ÙˆØ´ ÛÙˆÚº Ø³Ù†Ø¬Û’ Ø¯Øª\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 9 â€” Transformer Encoderâ€“Decoder Model  \n",
        "\n",
        "**Purpose:**  \n",
        "Define the complete Transformer model architecture.  \n",
        "Includes:  \n",
        "- **Token Embedding layer** â†’ converts token IDs to dense vectors.  \n",
        "- **Positional Encoding** â†’ adds order information.  \n",
        "- **Encoder & Decoder** â†’ learn context and generate responses.  \n",
        "- **Output Linear layer** â†’ maps hidden states to vocabulary logits.  \n",
        "\n",
        "**Core Concept:**  \n",
        "This is where **embeddings are created and learned** inside `nn.Embedding`.  \n"
      ],
      "metadata": {
        "id": "42tW3kejKUQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional encoding for Transformer\n",
        "    Adds position information to token embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=1024):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer Encoder-Decoder for Urdu Chatbot\n",
        "    Built from scratch following project guidelines\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab, d_model=512, nhead=8, enc_layers=4, dec_layers=4, ff=2048, drop=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tok_emb = nn.Embedding(vocab, d_model, padding_idx=PAD)\n",
        "\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.pos_dec = PositionalEncoding(d_model)\n",
        "\n",
        "        self.tf = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=enc_layers,\n",
        "            num_decoder_layers=dec_layers,\n",
        "            dim_feedforward=ff,\n",
        "            dropout=drop,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Output projection to vocabulary\n",
        "        self.fc_out = nn.Linear(d_model, vocab)\n",
        "\n",
        "        # Store config for logging\n",
        "        self.config = {\n",
        "            'vocab_size': vocab,\n",
        "            'd_model': d_model,\n",
        "            'nhead': nhead,\n",
        "            'enc_layers': enc_layers,\n",
        "            'dec_layers': dec_layers,\n",
        "            'ff': ff,\n",
        "            'dropout': drop\n",
        "        }\n",
        "\n",
        "    def forward(self, src_ids, tgt_in_ids, src_kpm, tgt_kpm, tgt_causal):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            src_ids: Source token IDs (B, S)\n",
        "            tgt_in_ids: Target input token IDs (B, T)\n",
        "            src_kpm: Source key padding mask (B, S)\n",
        "            tgt_kpm: Target key padding mask (B, T)\n",
        "            tgt_causal: Causal mask (T, T)\n",
        "\n",
        "        Returns:\n",
        "            logits: Output logits (B, T, V)\n",
        "        \"\"\"\n",
        "\n",
        "        src = self.pos_enc(self.tok_emb(src_ids))\n",
        "        tgt = self.pos_dec(self.tok_emb(tgt_in_ids))\n",
        "\n",
        "        out = self.tf(\n",
        "            src, tgt,\n",
        "            src_key_padding_mask=src_kpm,\n",
        "            tgt_key_padding_mask=tgt_kpm,\n",
        "            memory_key_padding_mask=src_kpm,\n",
        "            tgt_mask=tgt_causal\n",
        "        )\n",
        "\n",
        "        # Project to vocabulary\n",
        "        return self.fc_out(out)\n",
        "\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"  INITIALIZING MODEL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    'vocab': sp.get_piece_size(),\n",
        "    'd_model': 512,\n",
        "    'nhead': 2,\n",
        "    'enc_layers': 2,\n",
        "    'dec_layers': 2,\n",
        "    'ff': 2048,\n",
        "    'drop': 0.1\n",
        "}\n",
        "\n",
        "# Create model\n",
        "model = Seq2SeqTransformer(\n",
        "    vocab=MODEL_CONFIG['vocab'],\n",
        "    d_model=MODEL_CONFIG['d_model'],\n",
        "    nhead=MODEL_CONFIG['nhead'],\n",
        "    enc_layers=MODEL_CONFIG['enc_layers'],\n",
        "    dec_layers=MODEL_CONFIG['dec_layers'],\n",
        "    ff=MODEL_CONFIG['ff'],\n",
        "    drop=MODEL_CONFIG['drop']\n",
        ").to(DEVICE)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "embedding_params = model.tok_emb.weight.numel()\n",
        "transformer_params = total_params - embedding_params - model.fc_out.weight.numel()\n",
        "\n",
        "\n",
        "print(f\"\\n MODEL ARCHITECTURE\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"  Vocabulary Size:        {MODEL_CONFIG['vocab']:,}\")\n",
        "print(f\"  Embedding Dimension:    {MODEL_CONFIG['d_model']}\")\n",
        "print(f\"  Attention Heads:        {MODEL_CONFIG['nhead']}\")\n",
        "print(f\"  Encoder Layers:         {MODEL_CONFIG['enc_layers']}\")\n",
        "print(f\"  Decoder Layers:         {MODEL_CONFIG['dec_layers']}\")\n",
        "print(f\"  Feedforward Dimension:  {MODEL_CONFIG['ff']}\")\n",
        "print(f\"  Dropout Rate:           {MODEL_CONFIG['drop']}\")\n",
        "\n",
        "print(f\"\\n PARAMETER BREAKDOWN\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"  Total Parameters:       {total_params:,} ({total_params/1e6:.2f}M)\")\n",
        "print(f\"  Trainable Parameters:   {trainable_params:,} ({trainable_params/1e6:.2f}M)\")\n",
        "print(f\"  Embedding Parameters:   {embedding_params:,} ({embedding_params/1e6:.2f}M)\")\n",
        "print(f\"  Transformer Parameters: {transformer_params:,} ({transformer_params/1e6:.2f}M)\")\n",
        "\n",
        "print(f\"\\n GUIDELINE COMPLIANCE CHECK\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Check embedding dimension\n",
        "if MODEL_CONFIG['d_model'] in [256, 512]:\n",
        "    print(f\"   Embedding Dimension: {MODEL_CONFIG['d_model']} (Guideline: 256/512)\")\n",
        "else:\n",
        "    print(f\"    Embedding Dimension: {MODEL_CONFIG['d_model']} (Guideline suggests: 256/512)\")\n",
        "\n",
        "# Check attention heads\n",
        "if 2 <= MODEL_CONFIG['nhead'] <= 8:\n",
        "    print(f\"   Attention Heads: {MODEL_CONFIG['nhead']} (Guideline: 2-8)\")\n",
        "else:\n",
        "    print(f\"    Attention Heads: {MODEL_CONFIG['nhead']} (Guideline suggests: 2-8)\")\n",
        "\n",
        "# Check encoder layers\n",
        "print(f\"   Encoder Layers: {MODEL_CONFIG['enc_layers']} (Guideline: 2, using {MODEL_CONFIG['enc_layers']} for better quality)\")\n",
        "\n",
        "# Check decoder layers\n",
        "print(f\"   Decoder Layers: {MODEL_CONFIG['dec_layers']} (Guideline: 2, using {MODEL_CONFIG['dec_layers']} for better quality)\")\n",
        "\n",
        "# Check dropout\n",
        "if 0.1 <= MODEL_CONFIG['drop'] <= 0.3:\n",
        "    print(f\"   Dropout: {MODEL_CONFIG['drop']} (Guideline: 0.1-0.3)\")\n",
        "else:\n",
        "    print(f\"    Dropout: {MODEL_CONFIG['drop']} (Guideline suggests: 0.1-0.3)\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n LAYER-WISE PARAMETER COUNT\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "layer_params = {}\n",
        "for name, param in model.named_parameters():\n",
        "    layer_type = name.split('.')[0]\n",
        "    if layer_type not in layer_params:\n",
        "        layer_params[layer_type] = 0\n",
        "    layer_params[layer_type] += param.numel()\n",
        "\n",
        "for layer_type, count in sorted(layer_params.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / total_params) * 100\n",
        "    print(f\"  {layer_type:20s}: {count:12,} params ({percentage:5.2f}%)\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n TESTING MODEL FORWARD PASS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "try:\n",
        "\n",
        "    test_src = torch.randint(0, MODEL_CONFIG['vocab'], (2, 10), device=DEVICE)\n",
        "    test_tgt = torch.randint(0, MODEL_CONFIG['vocab'], (2, 8), device=DEVICE)\n",
        "    test_src_mask = (test_src == PAD)\n",
        "    test_tgt_mask = (test_tgt == PAD)\n",
        "    test_causal = torch.triu(torch.ones(8, 8, dtype=torch.bool, device=DEVICE), diagonal=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(test_src, test_tgt, test_src_mask, test_tgt_mask, test_causal)\n",
        "\n",
        "    print(f\"   Forward pass successful!\")\n",
        "    print(f\"  Input shape:   {test_src.shape}\")\n",
        "    print(f\"  Output shape:  {output.shape}\")\n",
        "    print(f\"  Expected:      (batch_size, seq_len, vocab_size)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   Forward pass failed: {e}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save model architecture\n",
        "MODEL_ARCHITECTURE_PATH = \"/content/model_architecture.txt\"\n",
        "with open(MODEL_ARCHITECTURE_PATH, \"w\") as f:\n",
        "    f.write(str(model))\n",
        "\n",
        "print(f\"\\n Model architecture saved to: {MODEL_ARCHITECTURE_PATH}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AI_XVryNmhs",
        "outputId": "d14614ed-1cbb-489d-f978-874371d73337"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "  INITIALIZING MODEL\n",
            "================================================================================\n",
            "\n",
            " MODEL ARCHITECTURE\n",
            "--------------------------------------------------------------------------------\n",
            "  Vocabulary Size:        20,000\n",
            "  Embedding Dimension:    512\n",
            "  Attention Heads:        2\n",
            "  Encoder Layers:         2\n",
            "  Decoder Layers:         2\n",
            "  Feedforward Dimension:  2048\n",
            "  Dropout Rate:           0.1\n",
            "\n",
            " PARAMETER BREAKDOWN\n",
            "--------------------------------------------------------------------------------\n",
            "  Total Parameters:       35,214,880 (35.21M)\n",
            "  Trainable Parameters:   35,214,880 (35.21M)\n",
            "  Embedding Parameters:   10,240,000 (10.24M)\n",
            "  Transformer Parameters: 14,734,880 (14.73M)\n",
            "\n",
            " GUIDELINE COMPLIANCE CHECK\n",
            "--------------------------------------------------------------------------------\n",
            "   Embedding Dimension: 512 (Guideline: 256/512)\n",
            "   Attention Heads: 2 (Guideline: 2-8)\n",
            "   Encoder Layers: 2 (Guideline: 2, using 2 for better quality)\n",
            "   Decoder Layers: 2 (Guideline: 2, using 2 for better quality)\n",
            "   Dropout: 0.1 (Guideline: 0.1-0.3)\n",
            "================================================================================\n",
            "\n",
            " LAYER-WISE PARAMETER COUNT\n",
            "--------------------------------------------------------------------------------\n",
            "  tf                  :   14,714,880 params (41.79%)\n",
            "  fc_out              :   10,260,000 params (29.14%)\n",
            "  tok_emb             :   10,240,000 params (29.08%)\n",
            "================================================================================\n",
            "\n",
            " TESTING MODEL FORWARD PASS\n",
            "--------------------------------------------------------------------------------\n",
            "   Forward pass successful!\n",
            "  Input shape:   torch.Size([2, 10])\n",
            "  Output shape:  torch.Size([2, 8, 20000])\n",
            "  Expected:      (batch_size, seq_len, vocab_size)\n",
            "================================================================================\n",
            "\n",
            " Model architecture saved to: /content/model_architecture.txt\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 10 â€” Loss Function, Optimizer, and Label Smoothing  \n",
        "\n",
        "**Purpose:**  \n",
        "Set up optimization pipeline:  \n",
        "- **Label Smoothing Loss** to prevent overconfidence.  \n",
        "- **Adam Optimizer** for stable gradient updates.  \n",
        "- **Gradient Clipping** to control exploding gradients.  \n",
        "\n",
        "**Outcome:**  \n",
        "Improved training stability and better generalization.  \n"
      ],
      "metadata": {
        "id": "czsqk-UgKWjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.1, ignore_index=PAD):\n",
        "        super().__init__()\n",
        "        self.conf = 1.0 - smoothing\n",
        "        self.smooth = smoothing\n",
        "        self.cls = classes\n",
        "        self.ignore = ignore_index\n",
        "    def forward(self, pred, target):\n",
        "        # pred: (B,T,V) ; target: (B,T)\n",
        "        pred = pred.reshape(-1, pred.size(-1))\n",
        "        target = target.reshape(-1)\n",
        "        mask = target != self.ignore\n",
        "        target = target[mask]\n",
        "        pred = pred[mask]\n",
        "        with torch.no_grad():\n",
        "            true = torch.zeros_like(pred)\n",
        "            true.fill_(self.smooth / (self.cls - 1))\n",
        "            true.scatter_(1, target.unsqueeze(1), self.conf)\n",
        "        return torch.mean(torch.sum(-true * F.log_softmax(pred, dim=-1), dim=-1))\n",
        "\n",
        "criterion = LabelSmoothingLoss(sp.get_piece_size(), smoothing=0.1, ignore_index=PAD)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "CLIP = 1.0\n"
      ],
      "metadata": {
        "id": "hjwXi_Q4NqKn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 11 â€” Training Loop (Teacher Forcing + Masks)  \n",
        "\n",
        "**Purpose:**  \n",
        "Train the model using teacher forcing.  \n",
        "The decoder receives the correct previous token (`t-1`) while predicting the next (`t`).  \n",
        "\n",
        "**Includes:**  \n",
        "- Padding and causal masks per batch  \n",
        "- Cross-entropy loss computation  \n",
        "- Gradient clipping and optimizer step  \n",
        "\n",
        "**Goal:**  \n",
        "Minimize sequence-to-sequence prediction error across epochs.  \n"
      ],
      "metadata": {
        "id": "r8DntTvrKYyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import sacrebleu\n",
        "import json\n",
        "\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH = 64\n",
        "MAX_LEN = 96\n",
        "CLIP = 1.0\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"  TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Epochs:          {EPOCHS}\")\n",
        "print(f\"  Batch Size:      {BATCH}\")\n",
        "print(f\"  Max Length:      {MAX_LEN}\")\n",
        "print(f\"  Gradient Clip:   {CLIP}\")\n",
        "print(f\"  Device:          {DEVICE}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def greedy_decode(text, max_new_tokens=64):\n",
        "    \"\"\"Generate response using greedy decoding\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Encode source: [BOS] + tokens + [EOS]\n",
        "    src_tokens = sp.encode(normalize_urdu(text), out_type=int)\n",
        "    if len(src_tokens) > MAX_LEN - 2:\n",
        "        src_tokens = src_tokens[:MAX_LEN - 2]\n",
        "\n",
        "    src_ids = torch.tensor([[BOS] + src_tokens + [EOS]], dtype=torch.long, device=DEVICE)\n",
        "    src_kpm = (src_ids == PAD)\n",
        "\n",
        "    ys = torch.tensor([[BOS]], dtype=torch.long, device=DEVICE)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        T = ys.size(1)\n",
        "        causal = torch.triu(torch.ones(T, T, dtype=torch.bool, device=DEVICE), diagonal=1)\n",
        "        logits = model(src_ids, ys, src_kpm, (ys == PAD), causal)\n",
        "        next_id = logits[:, -1, :].argmax(-1)\n",
        "        ys = torch.cat([ys, next_id.unsqueeze(1)], dim=1)\n",
        "        if next_id.item() == EOS:\n",
        "            break\n",
        "\n",
        "    out = ys[0, 1:]\n",
        "\n",
        "    if (out == EOS).any():\n",
        "        eos_idx = (out == EOS).nonzero(as_tuple=True)[0][0]\n",
        "        out = out[:eos_idx]\n",
        "\n",
        "    # Decode to text\n",
        "    return sp.decode(out.tolist())\n",
        "\n",
        "print(\" Greedy decode function defined\")\n",
        "\n",
        "\n",
        "def _val_bleu_sample(x_list, y_list, n=200):\n",
        "    \"\"\"Compute validation BLEU on a sample (fast)\"\"\"\n",
        "    model.eval()\n",
        "    n = min(n, len(x_list))\n",
        "    refs, hyps = [], []\n",
        "\n",
        "    for i in range(n):\n",
        "        try:\n",
        "            hyp = greedy_decode(x_list[i])\n",
        "            refs.append([y_list[i]])\n",
        "            hyps.append(hyp)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to decode sample {i}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not hyps:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        return sacrebleu.corpus_bleu(hyps, list(zip(*refs))[0]).score\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "print(\" BLEU computation function defined\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def _epoch_token_stats(logits, tgt_out):\n",
        "    \"\"\"\n",
        "    Calculate token-level accuracy\n",
        "    logits: (B,T,V), tgt_out: (B,T)\n",
        "    Returns: (correct_tokens, total_tokens_nonpad)\n",
        "    \"\"\"\n",
        "    pred_ids = logits.argmax(dim=-1)  # (B,T)\n",
        "    mask = (tgt_out != PAD)           # bool (B,T)\n",
        "    correct = (pred_ids.eq(tgt_out) & mask).sum().item()\n",
        "    total = mask.sum().item()\n",
        "    return correct, total\n",
        "\n",
        "print(\" Token accuracy function defined\")\n",
        "\n",
        "\n",
        "def train_or_eval(dataloader, train=True):\n",
        "    \"\"\"Train or evaluate for one epoch\"\"\"\n",
        "    model.train(train)\n",
        "    total_loss = 0.0\n",
        "    total_tok = 0\n",
        "    correct_tok = 0\n",
        "    total_tok_masked = 0\n",
        "\n",
        "    for batch_idx, (src, tgt_in, tgt_out, src_kpm, tgt_kpm, causal) in enumerate(dataloader):\n",
        "\n",
        "        src = src.to(DEVICE)\n",
        "        tgt_in = tgt_in.to(DEVICE)\n",
        "        tgt_out = tgt_out.to(DEVICE)\n",
        "        src_kpm = src_kpm.to(DEVICE)\n",
        "        tgt_kpm = tgt_kpm.to(DEVICE)\n",
        "        causal = causal.to(DEVICE)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        try:\n",
        "            logits = model(src, tgt_in, src_kpm, tgt_kpm, causal)\n",
        "            loss = criterion(logits, tgt_out)\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch {batch_idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        ntok = (tgt_out != PAD).sum().item()\n",
        "        total_loss += loss.item() * max(1, ntok)\n",
        "        total_tok += max(1, ntok)\n",
        "\n",
        "        # Token accuracy\n",
        "        corr, tot = _epoch_token_stats(logits, tgt_out)\n",
        "        correct_tok += corr\n",
        "        total_tok_masked += tot\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_loss = total_loss / total_tok if total_tok > 0 else float('inf')\n",
        "    ppl = math.exp(avg_loss) if avg_loss < 100 else float('inf')\n",
        "    acc = (correct_tok / total_tok_masked) if total_tok_masked > 0 else 0.0\n",
        "\n",
        "    return avg_loss, ppl, acc\n",
        "\n",
        "print(\" Train/eval function defined\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" STARTING TRAINING\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Dataset:\")\n",
        "print(f\"    Training:   {len(X_train):,} pairs\")\n",
        "print(f\"    Validation: {len(X_val):,} pairs\")\n",
        "print(f\"    Test:       {len(X_test):,} pairs\")\n",
        "print(f\"\\n  Model:\")\n",
        "print(f\"    Vocab size:     {sp.get_piece_size():,}\")\n",
        "print(f\"    Parameters:     {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"    Size:           {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "print(f\"\\n  Training:\")\n",
        "print(f\"    Epochs:         {EPOCHS}\")\n",
        "print(f\"    Batch size:     {BATCH}\")\n",
        "print(f\"    Learning rate:  {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "print(f\"    Optimizer:      {optimizer.__class__.__name__}\")\n",
        "print(f\"    Device:         {DEVICE}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "best_val_bleu = -1.0\n",
        "best_val_ppl = float('inf')\n",
        "best_bleu_ckpt = '/content/best_bleu_urdu_chatbot.pt'\n",
        "best_ppl_ckpt = '/content/best_ppl_urdu_chatbot.pt'\n",
        "patience_counter = 0\n",
        "PATIENCE = 5\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "print(\"\\n Training variables initialized\")\n",
        "print(f\"   Early stopping patience: {PATIENCE}\")\n",
        "print(f\"   LR scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" TRAINING LOOP STARTED\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "training_start_time = time.time()\n",
        "\n",
        "for ep in range(1, EPOCHS + 1):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    tr_loss, tr_ppl, tr_acc = train_or_eval(train_dl, train=True)\n",
        "\n",
        "    va_loss, va_ppl, va_acc = train_or_eval(valid_dl, train=False)\n",
        "\n",
        "    old_lr = optimizer.param_groups[0]['lr']\n",
        "    scheduler.step(va_ppl)\n",
        "    new_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    if ep % 2 == 0 or ep == 1:\n",
        "        val_bleu = _val_bleu_sample(list(X_val), list(y_val), n=200)\n",
        "    else:\n",
        "        val_bleu = best_val_bleu\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    print(\n",
        "        f\"Epoch {ep:02d}/{EPOCHS} | \"\n",
        "        f\"train_ppl={tr_ppl:6.2f} train_acc={tr_acc*100:5.2f}% | \"\n",
        "        f\"valid_ppl={va_ppl:6.2f} valid_acc={va_acc*100:5.2f}% | \"\n",
        "        f\"valid_BLEU={val_bleu:5.2f} | \"\n",
        "        f\"lr={new_lr:.2e} | \"\n",
        "        f\"time={epoch_time:.1f}s\"\n",
        "    )\n",
        "\n",
        "    # Save best BLEU model\n",
        "    if val_bleu > best_val_bleu:\n",
        "        improvement = val_bleu - best_val_bleu\n",
        "        best_val_bleu = val_bleu\n",
        "        patience_counter = 0\n",
        "\n",
        "        torch.save({\n",
        "            'epoch': ep,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'vocab_size': sp.get_piece_size(),\n",
        "            'best_val_bleu': best_val_bleu,\n",
        "            'best_val_ppl': va_ppl,\n",
        "            'config': model.config if hasattr(model, 'config') else {}\n",
        "        }, best_bleu_ckpt)\n",
        "        print(f\"   Saved best BLEU! (+{improvement:.2f}) â†’ {best_bleu_ckpt}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"   No BLEU improvement ({patience_counter}/{PATIENCE})\")\n",
        "\n",
        "    if va_ppl < best_val_ppl:\n",
        "        best_val_ppl = va_ppl\n",
        "        torch.save({\n",
        "            'epoch': ep,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'vocab_size': sp.get_piece_size(),\n",
        "            'best_val_ppl': best_val_ppl,\n",
        "            'best_val_bleu': val_bleu,\n",
        "            'config': model.config if hasattr(model, 'config') else {}\n",
        "        }, best_ppl_ckpt)\n",
        "        print(f\"   Saved best PPL! ({va_ppl:.2f}) â†’ {best_ppl_ckpt}\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f\"\\n  Early stopping triggered at epoch {ep}\")\n",
        "        print(f\"    No BLEU improvement for {PATIENCE} consecutive epochs\")\n",
        "        break\n",
        "\n",
        "    if new_lr != old_lr:\n",
        "        print(f\"   Learning rate reduced: {old_lr:.2e} â†’ {new_lr:.2e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "total_training_time = time.time() - training_start_time\n",
        "hours = int(total_training_time // 3600)\n",
        "minutes = int((total_training_time % 3600) // 60)\n",
        "seconds = int(total_training_time % 60)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" TRAINING COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Total training time:    {hours}h {minutes}m {seconds}s\")\n",
        "print(f\"  Epochs completed:       {ep}/{EPOCHS}\")\n",
        "print(f\"  Best validation BLEU:   {best_val_bleu:.2f}\")\n",
        "print(f\"  Best validation PPL:    {best_val_ppl:.2f}\")\n",
        "print(f\"\\n  Saved checkpoints:\")\n",
        "print(f\"    Best BLEU:  {best_bleu_ckpt}\")\n",
        "print(f\"    Best PPL:   {best_ppl_ckpt}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n",
        "print(\"\\n Evaluating on test set...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "test_loss, test_ppl, test_acc = train_or_eval(test_dl, train=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" FINAL TEST METRICS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"  Test Loss:        {test_loss:.4f}\")\n",
        "print(f\"  Test Perplexity:  {test_ppl:.2f}\")\n",
        "print(f\"  Test Accuracy:    {test_acc*100:.2f}%\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "training_history = {\n",
        "    'training_config': {\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH,\n",
        "        'max_length': MAX_LEN,\n",
        "        'clip_value': CLIP,\n",
        "        'learning_rate': 3e-4,\n",
        "        'optimizer': 'Adam',\n",
        "        'scheduler': 'ReduceLROnPlateau'\n",
        "    },\n",
        "    'model_config': {\n",
        "        'vocab_size': sp.get_piece_size(),\n",
        "        'total_params': sum(p.numel() for p in model.parameters()),\n",
        "        'd_model': 512,\n",
        "        'nhead': 8,\n",
        "        'enc_layers': 4,\n",
        "        'dec_layers': 4\n",
        "    },\n",
        "    'results': {\n",
        "        'best_val_bleu': float(best_val_bleu),\n",
        "        'best_val_ppl': float(best_val_ppl),\n",
        "        'test_loss': float(test_loss),\n",
        "        'test_ppl': float(test_ppl),\n",
        "        'test_acc': float(test_acc),\n",
        "        'epochs_completed': ep,\n",
        "        'training_time_seconds': float(total_training_time)\n",
        "    },\n",
        "    'dataset': {\n",
        "        'train_size': len(X_train),\n",
        "        'val_size': len(X_val),\n",
        "        'test_size': len(X_test),\n",
        "        'total_pairs': len(X_train) + len(X_val) + len(X_test)\n",
        "    }\n",
        "}\n",
        "\n",
        "history_path = '/content/training_history.json'\n",
        "with open(history_path, 'w') as f:\n",
        "    json.dump(training_history, f, indent=2)\n",
        "\n",
        "print(f\"\\n Training history saved to: {history_path}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\" TESTING RESPONSE GENERATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "test_inputs = [\n",
        "    \"Ø³Ù„Ø§Ù…\",\n",
        "    \"Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\",\n",
        "    \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\"\n",
        "]\n",
        "\n",
        "# Load best BLEU model\n",
        "print(f\"\\n Loading best BLEU model: {best_bleu_ckpt}\")\n",
        "checkpoint = torch.load(best_bleu_ckpt, map_location=DEVICE)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"\\nğŸ’¬ Sample Responses:\\n\")\n",
        "for i, inp in enumerate(test_inputs, 1):\n",
        "    try:\n",
        "        response = greedy_decode(inp)\n",
        "        print(f\"{i}. Input:  {inp}\")\n",
        "        print(f\"   Output: {response}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"{i}. Input:  {inp}\")\n",
        "        print(f\"   Error:  {e}\\n\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\" ALL TRAINING COMPLETE!\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nğŸ“Œ Next Steps:\")\n",
        "print(\"   1. Check training_history.json for detailed metrics\")\n",
        "print(\"   2. Load best model from checkpoints\")\n",
        "print(\"   3. Run comprehensive evaluation (Cell 13)\")\n",
        "print(\"   4. Deploy chatbot interface (Gradio/Streamlit)\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "2-2ggeedNs-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec9f48e-1708-4787-ec59-36413963ca98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "  TRAINING CONFIGURATION\n",
            "================================================================================\n",
            "  Epochs:          30\n",
            "  Batch Size:      64\n",
            "  Max Length:      96\n",
            "  Gradient Clip:   1.0\n",
            "  Device:          cuda\n",
            "================================================================================\n",
            " Greedy decode function defined\n",
            " BLEU computation function defined\n",
            " Token accuracy function defined\n",
            " Train/eval function defined\n",
            "\n",
            "================================================================================\n",
            " STARTING TRAINING\n",
            "================================================================================\n",
            "  Dataset:\n",
            "    Training:   50,568 pairs\n",
            "    Validation: 6,321 pairs\n",
            "    Test:       6,322 pairs\n",
            "\n",
            "  Model:\n",
            "    Vocab size:     20,000\n",
            "    Parameters:     35,214,880\n",
            "    Size:           35.21M\n",
            "\n",
            "  Training:\n",
            "    Epochs:         30\n",
            "    Batch size:     64\n",
            "    Learning rate:  3.00e-04\n",
            "    Optimizer:      Adam\n",
            "    Device:         cuda\n",
            "================================================================================\n",
            "\n",
            " Training variables initialized\n",
            "   Early stopping patience: 5\n",
            "   LR scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\n",
            "\n",
            "================================================================================\n",
            " TRAINING LOOP STARTED\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/30 | train_ppl=135.05 train_acc=40.60% | valid_ppl= 70.11 valid_acc=47.88% | valid_BLEU= 1.16 | lr=3.00e-04 | time=82.6s\n",
            "   Saved best BLEU! (+2.16) â†’ /content/best_bleu_urdu_chatbot.pt\n",
            "   Saved best PPL! (70.11) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "Epoch 02/30 | train_ppl= 46.83 train_acc=52.09% | valid_ppl= 36.18 valid_acc=56.34% | valid_BLEU= 0.79 | lr=3.00e-04 | time=84.6s\n",
            "   No BLEU improvement (1/5)\n",
            "   Saved best PPL! (36.18) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "Epoch 03/30 | train_ppl= 24.13 train_acc=62.15% | valid_ppl= 23.58 valid_acc=63.54% | valid_BLEU= 1.16 | lr=3.00e-04 | time=76.6s\n",
            "   No BLEU improvement (2/5)\n",
            "   Saved best PPL! (23.58) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "Epoch 04/30 | train_ppl= 15.65 train_acc=69.58% | valid_ppl= 17.99 valid_acc=68.36% | valid_BLEU= 0.69 | lr=3.00e-04 | time=87.9s\n",
            "   No BLEU improvement (3/5)\n",
            "   Saved best PPL! (17.99) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "Epoch 05/30 | train_ppl= 11.85 train_acc=74.68% | valid_ppl= 15.33 valid_acc=71.83% | valid_BLEU= 1.16 | lr=3.00e-04 | time=77.5s\n",
            "   No BLEU improvement (4/5)\n",
            "   Saved best PPL! (15.33) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "Epoch 06/30 | train_ppl=  9.84 train_acc=78.48% | valid_ppl= 14.13 valid_acc=73.28% | valid_BLEU= 0.76 | lr=3.00e-04 | time=88.4s\n",
            "   No BLEU improvement (5/5)\n",
            "   Saved best PPL! (14.13) â†’ /content/best_ppl_urdu_chatbot.pt\n",
            "\n",
            "  Early stopping triggered at epoch 6\n",
            "    No BLEU improvement for 5 consecutive epochs\n",
            "\n",
            "================================================================================\n",
            " TRAINING COMPLETE!\n",
            "================================================================================\n",
            "  Total training time:    0h 8m 55s\n",
            "  Epochs completed:       6/30\n",
            "  Best validation BLEU:   1.16\n",
            "  Best validation PPL:    14.13\n",
            "\n",
            "  Saved checkpoints:\n",
            "    Best BLEU:  /content/best_bleu_urdu_chatbot.pt\n",
            "    Best PPL:   /content/best_ppl_urdu_chatbot.pt\n",
            "================================================================================\n",
            "\n",
            " Evaluating on test set...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            " FINAL TEST METRICS\n",
            "================================================================================\n",
            "  Test Loss:        2.6330\n",
            "  Test Perplexity:  13.91\n",
            "  Test Accuracy:    73.67%\n",
            "================================================================================\n",
            "\n",
            " Training history saved to: /content/training_history.json\n",
            "\n",
            "================================================================================\n",
            " TESTING RESPONSE GENERATION\n",
            "================================================================================\n",
            "\n",
            " Loading best BLEU model: /content/best_bleu_urdu_chatbot.pt\n",
            "\n",
            "ğŸ’¬ Sample Responses:\n",
            "\n",
            "1. Input:  Ø³Ù„Ø§Ù…\n",
            "   Output: ÛŒÛ\n",
            "\n",
            "2. Input:  Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\n",
            "   Output: Ú©ÛŒØ§ ÛÛ’\n",
            "\n",
            "3. Input:  Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\n",
            "   Output: Ø§Ù¾ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ú©ÛŒØ§ ÛÛ’\n",
            "\n",
            "================================================================================\n",
            " ALL TRAINING COMPLETE!\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Œ Next Steps:\n",
            "   1. Check training_history.json for detailed metrics\n",
            "   2. Load best model from checkpoints\n",
            "   3. Run comprehensive evaluation (Cell 13)\n",
            "   4. Deploy chatbot interface (Gradio/Streamlit)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "model_config = {}\n",
        "\n",
        "if hasattr(model, '__init__'):\n",
        "\n",
        "    try:\n",
        "        model_config['vocab_size'] = model.tok_emb.num_embeddings\n",
        "        model_config['d_model'] = model.tok_emb.embedding_dim\n",
        "        model_config['nhead'] = model.tf.nhead\n",
        "        model_config['encoder_layers'] = model.tf.encoder.num_layers\n",
        "        model_config['decoder_layers'] = model.tf.decoder.num_layers\n",
        "        model_config['dim_feedforward'] = model.tf.encoder.layers[0].linear1.out_features\n",
        "        model_config['dropout'] = model.tf.encoder.layers[0].dropout.p\n",
        "    except:\n",
        "\n",
        "        model_config = {\n",
        "            'vocab_size': sp.get_piece_size(),\n",
        "            'd_model': 'Unknown',\n",
        "            'nhead': 'Unknown',\n",
        "            'encoder_layers': 'Unknown',\n",
        "            'decoder_layers': 'Unknown',\n",
        "            'dim_feedforward': 'Unknown',\n",
        "            'dropout': 'Unknown'\n",
        "        }\n",
        "\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "non_trainable_params = total_params - trainable_params\n",
        "\n",
        "\n",
        "model_size_mb = total_params * 4 / (1024 ** 2)\n",
        "\n",
        "optimizer_name = optimizer.__class__.__name__\n",
        "learning_rate = optimizer.param_groups[0]['lr']\n",
        "if 'betas' in optimizer.param_groups[0]:\n",
        "    betas = optimizer.param_groups[0]['betas']\n",
        "else:\n",
        "    betas = 'N/A'\n",
        "\n",
        "# Print formatted summary\n",
        "print(\"=\" * 70)\n",
        "print(\" FINAL MODEL CONFIGURATION\".center(70))\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\n TOKENIZER:\")\n",
        "print(f\"  â€¢ Vocabulary Size:        {sp.get_piece_size():,}\")\n",
        "print(f\"  â€¢ Special Tokens:         [PAD]={PAD}, [BOS]={BOS}, [EOS]={EOS}, [UNK]={UNK}\")\n",
        "print(f\"  â€¢ Max Sequence Length:    {MAX_LEN}\")\n",
        "\n",
        "print(\"\\n  MODEL ARCHITECTURE:\")\n",
        "print(f\"  â€¢ Embedding Dimension:    {model_config['d_model']}\")\n",
        "print(f\"  â€¢ Attention Heads:        {model_config['nhead']}\")\n",
        "print(f\"  â€¢ Encoder Layers:         {model_config['encoder_layers']}\")\n",
        "print(f\"  â€¢ Decoder Layers:         {model_config['decoder_layers']}\")\n",
        "print(f\"  â€¢ Feedforward Dimension:  {model_config['dim_feedforward']}\")\n",
        "print(f\"  â€¢ Dropout:                {model_config['dropout']}\")\n",
        "\n",
        "print(\"\\n PARAMETERS:\")\n",
        "print(f\"  â€¢ Total Parameters:       {total_params:,} ({total_params/1e6:.2f}M)\")\n",
        "print(f\"  â€¢ Trainable Parameters:   {trainable_params:,} ({trainable_params/1e6:.2f}M)\")\n",
        "if non_trainable_params > 0:\n",
        "    print(f\"  â€¢ Non-trainable Params:   {non_trainable_params:,}\")\n",
        "print(f\"  â€¢ Model Size:             {model_size_mb:.2f} MB\")\n",
        "\n",
        "print(\"\\n  TRAINING CONFIGURATION:\")\n",
        "print(f\"  â€¢ Optimizer:              {optimizer_name}\")\n",
        "print(f\"  â€¢ Learning Rate:          {learning_rate:.2e}\")\n",
        "if betas != 'N/A':\n",
        "    print(f\"  â€¢ Betas:                  {betas}\")\n",
        "print(f\"  â€¢ Gradient Clipping:      {CLIP}\")\n",
        "print(f\"  â€¢ Batch Size:             {BATCH}\")\n",
        "print(f\"  â€¢ Total Epochs:           {EPOCHS}\")\n",
        "\n",
        "print(\"\\n DATASET:\")\n",
        "print(f\"  â€¢ Training Samples:       {len(X_train):,}\")\n",
        "print(f\"  â€¢ Validation Samples:     {len(X_val):,}\")\n",
        "print(f\"  â€¢ Test Samples:           {len(X_test):,}\")\n",
        "print(f\"  â€¢ Batches per Epoch:      {len(train_dl):,}\")\n",
        "\n",
        "print(\"\\n TRAINING RESULTS:\")\n",
        "print(f\"  â€¢ Best Validation PPL:    {best_val_ppl:.2f}\")\n",
        "print(f\"  â€¢ Epochs Completed:       {ep if 'ep' in locals() else 'N/A'}\")\n",
        "print(f\"  â€¢ Final Learning Rate:    {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "print(\"\\nSAVED MODELS:\")\n",
        "print(f\"  â€¢ Best Model:             /content/best_urdu_chatbot_model.pt\")\n",
        "print(f\"  â€¢ Final Model:            /content/final_urdu_chatbot_model.pt\")\n",
        "\n",
        "print(\"\\n  HARDWARE:\")\n",
        "print(f\"  â€¢ Device:                 {DEVICE}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  â€¢ GPU:                    {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  â€¢ GPU Memory:             {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Additional breakdown by layer type\n",
        "print(\"\\n PARAMETER BREAKDOWN BY LAYER TYPE:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "layer_params = {}\n",
        "for name, param in model.named_parameters():\n",
        "    layer_type = name.split('.')[0]\n",
        "    if layer_type not in layer_params:\n",
        "        layer_params[layer_type] = 0\n",
        "    layer_params[layer_type] += param.numel()\n",
        "\n",
        "for layer_type, count in sorted(layer_params.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / total_params) * 100\n",
        "    print(f\"  â€¢ {layer_type:20s}: {count:12,} ({percentage:5.2f}%)\")\n",
        "\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "M4YAHvYbtvVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a77f58-61c3-4200-f091-9a00e6f0c97e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "                       FINAL MODEL CONFIGURATION                      \n",
            "======================================================================\n",
            "\n",
            " TOKENIZER:\n",
            "  â€¢ Vocabulary Size:        20,000\n",
            "  â€¢ Special Tokens:         [PAD]=0, [BOS]=1, [EOS]=2, [UNK]=3\n",
            "  â€¢ Max Sequence Length:    96\n",
            "\n",
            "  MODEL ARCHITECTURE:\n",
            "  â€¢ Embedding Dimension:    512\n",
            "  â€¢ Attention Heads:        2\n",
            "  â€¢ Encoder Layers:         2\n",
            "  â€¢ Decoder Layers:         2\n",
            "  â€¢ Feedforward Dimension:  2048\n",
            "  â€¢ Dropout:                0.1\n",
            "\n",
            " PARAMETERS:\n",
            "  â€¢ Total Parameters:       35,214,880 (35.21M)\n",
            "  â€¢ Trainable Parameters:   35,214,880 (35.21M)\n",
            "  â€¢ Model Size:             134.33 MB\n",
            "\n",
            "  TRAINING CONFIGURATION:\n",
            "  â€¢ Optimizer:              Adam\n",
            "  â€¢ Learning Rate:          3.00e-04\n",
            "  â€¢ Betas:                  (0.9, 0.999)\n",
            "  â€¢ Gradient Clipping:      1.0\n",
            "  â€¢ Batch Size:             64\n",
            "  â€¢ Total Epochs:           30\n",
            "\n",
            " DATASET:\n",
            "  â€¢ Training Samples:       50,568\n",
            "  â€¢ Validation Samples:     6,321\n",
            "  â€¢ Test Samples:           6,322\n",
            "  â€¢ Batches per Epoch:      791\n",
            "\n",
            " TRAINING RESULTS:\n",
            "  â€¢ Best Validation PPL:    14.13\n",
            "  â€¢ Epochs Completed:       6\n",
            "  â€¢ Final Learning Rate:    3.00e-04\n",
            "\n",
            "SAVED MODELS:\n",
            "  â€¢ Best Model:             /content/best_urdu_chatbot_model.pt\n",
            "  â€¢ Final Model:            /content/final_urdu_chatbot_model.pt\n",
            "\n",
            "  HARDWARE:\n",
            "  â€¢ Device:                 cuda\n",
            "  â€¢ GPU:                    Tesla T4\n",
            "  â€¢ GPU Memory:             15.83 GB\n",
            "======================================================================\n",
            "\n",
            " PARAMETER BREAKDOWN BY LAYER TYPE:\n",
            "----------------------------------------------------------------------\n",
            "  â€¢ tf                  :   14,714,880 (41.79%)\n",
            "  â€¢ fc_out              :   10,260,000 (29.14%)\n",
            "  â€¢ tok_emb             :   10,240,000 (29.08%)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ’¡ Cell 12 â€” Greedy Decoding and Quick BLEU Evaluation  \n",
        "\n",
        "**Purpose:**  \n",
        "Generate Urdu responses token-by-token using **greedy decoding**  \n",
        "and evaluate them on a small validation set using the **BLEU score**.  \n",
        "\n",
        "**Why:**  \n",
        "Provides a quick measure of model performance after training.  \n"
      ],
      "metadata": {
        "id": "Chj2_NuHKbi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def greedy_decode(text, max_new_tokens=64):\n",
        "    \"\"\"\n",
        "    Generate response using greedy decoding with proper special tokens.\n",
        "\n",
        "    Args:\n",
        "        text: Input Urdu text\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "\n",
        "    Returns:\n",
        "        Generated Urdu text\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        src_tokens = sp.encode(normalize_urdu(text), out_type=int)\n",
        "        if len(src_tokens) > MAX_LEN - 2:\n",
        "            src_tokens = src_tokens[:MAX_LEN - 2]\n",
        "\n",
        "        src_ids = torch.tensor([[BOS] + src_tokens + [EOS]], device=DEVICE)\n",
        "        src_kpm = (src_ids == PAD)\n",
        "\n",
        "        ys = torch.tensor([[BOS]], device=DEVICE)\n",
        "\n",
        "        for _ in range(max_new_tokens):\n",
        "            T = ys.size(1)\n",
        "            causal = torch.triu(torch.ones(T, T, dtype=torch.bool, device=DEVICE), diagonal=1)\n",
        "            logits = model(src_ids, ys, src_kpm, (ys == PAD), causal)\n",
        "\n",
        "            next_id = logits[:, -1, :].argmax(-1)\n",
        "\n",
        "            ys = torch.cat([ys, next_id.unsqueeze(1)], dim=1)\n",
        "\n",
        "            if next_id.item() == EOS:\n",
        "                break\n",
        "\n",
        "        out = ys[0, 1:]\n",
        "        if (out == EOS).any():\n",
        "            eos_idx = (out == EOS).nonzero(as_tuple=True)[0][0]\n",
        "            out = out[:eos_idx]\n",
        "\n",
        "        return sp.decode(out.tolist())\n",
        "\n",
        "print(\" Testing Generation:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_inputs = [\n",
        "    \"Ø³Ù„Ø§Ù…\",\n",
        "    \"Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\",\n",
        "    \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\"\n",
        "]\n",
        "\n",
        "for inp in test_inputs:\n",
        "    gen = greedy_decode(inp)\n",
        "    print(f\"\\nInput:  {inp}\")\n",
        "    print(f\"Output: {gen}\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "Be7BuZJNNvXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70951e6d-b4c3-4fe2-a186-4be4b0bf56c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Testing Generation:\n",
            "============================================================\n",
            "\n",
            "Input:  Ø³Ù„Ø§Ù…\n",
            "Output: ÛŒÛ\n",
            "\n",
            "Input:  Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\n",
            "Output: Ú©ÛŒØ§ ÛÛ’\n",
            "\n",
            "Input:  Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\n",
            "Output: Ø§Ù¾ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ú©ÛŒØ§ ÛÛ’\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VCKwxGmx7EYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 13 â€” Compute chrF & ROUGE-L (Comprehensive Evaluation)  \n",
        "\n",
        "**Purpose:**  \n",
        "Complement BLEU with additional metrics:  \n",
        "- **chrF:** character-level F-score (good for morphologically rich Urdu)  \n",
        "- **ROUGE-L:** longest common subsequence overlap (fluency indicator).  \n",
        "\n",
        "**Outcome:**  \n",
        "Better overall assessment of model quality.  \n"
      ],
      "metadata": {
        "id": "Av9UuZMSKdvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def full_metrics(xs, ys, n=100):\n",
        "    \"\"\"Compute BLEU, chrF, ROUGE-L, and Perplexity\"\"\"\n",
        "    refs, hyps = [], []\n",
        "\n",
        "    print(f\"Generating responses for {min(n, len(xs))} samples...\")\n",
        "    for i in range(min(n, len(xs))):\n",
        "        hyp = greedy_decode(xs[i])\n",
        "        refs.append([ys[i]])\n",
        "        hyps.append(hyp)\n",
        "        if (i+1) % 20 == 0:\n",
        "            print(f\"  Progress: {i+1}/{min(n, len(xs))}\")\n",
        "\n",
        "\n",
        "    bleu = sacrebleu.corpus_bleu(hyps, list(map(list, zip(*refs)))).score\n",
        "    chrf = sacrebleu.corpus_chrf(hyps, list(map(list, zip(*refs)))).score\n",
        "    rs = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n",
        "    rl = np.mean([rs.score(r[0], h)['rougeL'].fmeasure for h, r in zip(hyps, refs)])\n",
        "\n",
        "    test_ds = PairDS(list(xs[:n]), list(ys[:n]), sp)\n",
        "    test_dl_eval = DataLoader(test_ds, batch_size=BATCH, collate_fn=collate, shuffle=False)\n",
        "    _, ppl, _ = train_or_eval(test_dl_eval, train=False)\n",
        "\n",
        "    return {\n",
        "        \"BLEU\": round(bleu, 2),\n",
        "        \"chrF\": round(chrf, 2),\n",
        "        \"ROUGE-L(F)\": round(rl, 3),\n",
        "        \"Perplexity\": round(ppl, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"\\n Computing Test Set Metrics...\")\n",
        "metrics = full_metrics(list(X_test), list(y_test), n=100)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\" EVALUATION RESULTS (Test Set)\")\n",
        "print(\"=\" * 60)\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"  {metric:15s}: {value}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "print(\"\\n Sample Predictions:\")\n",
        "print(\"=\" * 60)\n",
        "for i in range(min(5, len(X_test))):\n",
        "    src = X_test[i]\n",
        "    ref = y_test[i]\n",
        "    gen = greedy_decode(src)\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"  Input:     {src}\")\n",
        "    print(f\"  Reference: {ref}\")\n",
        "    print(f\"  Generated: {gen}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "wEitq-TFNyE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52509b81-d5f3-43fe-e674-122d37340167"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Computing Test Set Metrics...\n",
            "Generating responses for 100 samples...\n",
            "  Progress: 20/100\n",
            "  Progress: 40/100\n",
            "  Progress: 60/100\n",
            "  Progress: 80/100\n",
            "  Progress: 100/100\n",
            "\n",
            "============================================================\n",
            " EVALUATION RESULTS (Test Set)\n",
            "============================================================\n",
            "  BLEU           : 4.85\n",
            "  chrF           : 17.5\n",
            "  ROUGE-L(F)     : 0.24\n",
            "  Perplexity     : 60.24\n",
            "============================================================\n",
            "\n",
            " Sample Predictions:\n",
            "============================================================\n",
            "\n",
            "Example 1:\n",
            "  Input:     Ø§Ø¹Ø¸Ù…ÛŒ Ú©Ùˆ Ú¯Ø§Ú‘ÛŒ Ú©ÛŒ Ù¾Ú†ÛÙ„ÛŒ [SEP] Ø§ÛŒÚ© Ø¯Ù† Ú©Û’ Ú©ÛÛŒÙ„ Ú©Ø§ Ù…Ø§ÛØ±\n",
            "  Reference: Ø¬Ø¨ Ø§ØµÙ„ Ù¾Ø§Ú©Ø³ØªØ§Ù† Ø¨Ù† Ø±ÛØ§ ØªÛØ§, ØªØ¨ ØªÙˆ Ø§ÛŒØ³Ø§ Ù†ÛÛŒÚº ØªÛØ§.\n",
            "  Generated: ÛŒÛ Ø¨Ø§Øª ÛÛ’ Ú©Û ÙˆÛ Ø§Ø³ Ú©Ø§ Ø§ÛŒÚ© ÙˆÙ‚Øª ÛÛ’.\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 2:\n",
            "  Input:     Ø§Ø³ Ú©ÛŒ Ø§Ù†Ú©ÛÙˆÚº Ø³Û’ Ú¯Ø± Ù¾Ú‘Û’. [SEP] Ø§Ù¾ Ú©ÛØ§Úº Ø³Û’ ÛÛŒÚº\n",
            "  Reference: Ø´Ø§Ø¹Ø±ÛŒ Ú©Û’ Ù‚Ù„Ù… Ø³Û’ Ú©Ø§ØºØ° Ù¾Ø± Ø§ØªØ§Ø±Ø§ ÛÛ’\n",
            "  Generated: Ø§Ø³ Ú©ÛŒ Ø·Ø±Ø­ Ù…ÛŒÚº Ø¨ÛØª Ø³Û’ Ø²ÛŒØ§Ø¯Û ÛÛ’.\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 3:\n",
            "  Input:     Ù¾ÛŒØ§Ù„Û’ Ù…ÛŒÚº Ø§ÛŒÚ© Ú†Ù…Ú† [MASK0] [MASK1] Ù„ÛŒÙ…ÙˆÚº Ú©Ø§ Ø±Ø³ Ù†Ú†ÙˆÚ‘ÛŒÚº\n",
            "  Reference: [SPAN0] Ù¾Ø§Ù†ÛŒ [SPAN1] Ú©Û’ Ø³Ø§ØªÛ Ø§ÛŒÚ©\n",
            "  Generated: [SPAN0] Ú©Ø§ Ø§ÛŒÚ© [SPAN1] Ø§ÙˆØ±\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 4:\n",
            "  Input:     Ø±ÙˆØ§Úº Ø§Ø±Ø¯Ùˆ Ú©ÛŒ [CONTINUE]\n",
            "  Reference: ØºØ±Ø¶ Ø³Û’ Ú¯Ø±ÛŒÙ† ÛØ§ÙˆØ³ Ú©Ùˆ Ø³Ø¨Ø² Ù…Ú©Ø§Ù†\n",
            "  Generated: Ú©ÛŒ Ø¬Ø§Ù†Ø¨ Ø³Û’ Ù…Ù„Ø§Ù‚Ø§Øª\n",
            "------------------------------------------------------------\n",
            "\n",
            "Example 5:\n",
            "  Input:     Ø§Ø®Ø¨Ø§Ø± Ø·Ø±Ø­ Ø±Ù¾ÙˆØ±Ù¹ Ø§Ø³ Ø§ØºØ§Ø² Ú©Ø§ Ú©Ø±ØªØ§ ÛÛ’\n",
            "  Reference: Ø§Ø®Ø¨Ø§Ø± Ø±Ù¾ÙˆØ±Ù¹ Ú©Ø§ Ø§ØºØ§Ø² Ø§Ø³ Ø·Ø±Ø­ Ú©Ø±ØªØ§ ÛÛ’\n",
            "  Generated: Ø§Ø³ Ú©Ø§ Ø§Ø³ Ø·Ø±Ø­ Ø§Ø³ Ø·Ø±Ø­ ÛÛ’\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNHcFGFqOivx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Cell 15 â€” Beam Search Decoding  \n",
        "\n",
        "**Purpose:**  \n",
        "Improve generation quality using **beam search**,  \n",
        "which explores multiple candidate sequences before choosing the best.  \n",
        "\n",
        "**Effect:**  \n",
        "Produces smoother and more coherent Urdu replies compared to greedy decoding.  \n"
      ],
      "metadata": {
        "id": "oy00kpWNKiSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_decode(text, beam_width=3, max_new_tokens=64):\n",
        "    \"\"\"\n",
        "    Beam search decoding for better quality responses\n",
        "\n",
        "    Args:\n",
        "        text: Input Urdu text\n",
        "        beam_width: Number of beams to maintain\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "\n",
        "    Returns:\n",
        "        Decoded Urdu text\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        src_ids = torch.tensor(\n",
        "            [[BOS] + sp.encode(normalize_urdu(text), out_type=int)[:MAX_LEN-2] + [EOS]],\n",
        "            device=DEVICE\n",
        "        )\n",
        "        src_kpm = (src_ids == PAD)\n",
        "\n",
        "\n",
        "        beams = [(0.0, torch.tensor([[BOS]], device=DEVICE))]\n",
        "        completed_beams = []\n",
        "\n",
        "        for step in range(max_new_tokens):\n",
        "            candidates = []\n",
        "\n",
        "            for score, seq in beams:\n",
        "\n",
        "                if seq[0, -1].item() == EOS:\n",
        "                    completed_beams.append((score / len(seq[0]), seq))  # Normalize by length\n",
        "                    continue\n",
        "\n",
        "                # Generate next token probabilities\n",
        "                T = seq.size(1)\n",
        "                causal = torch.triu(torch.ones(T, T, dtype=torch.bool, device=DEVICE), diagonal=1)\n",
        "                logits = model(src_ids, seq, src_kpm, (seq == PAD), causal)\n",
        "                log_probs = F.log_softmax(logits[:, -1, :], dim=-1)\n",
        "\n",
        "                # Get top-k next tokens\n",
        "                topk_probs, topk_ids = torch.topk(log_probs, beam_width)\n",
        "\n",
        "                for prob, token_id in zip(topk_probs[0], topk_ids[0]):\n",
        "                    new_seq = torch.cat([seq, token_id.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "                    new_score = score + prob.item()\n",
        "                    candidates.append((new_score, new_seq))\n",
        "\n",
        "            # Keep top beam_width candidates\n",
        "            beams = sorted(candidates, key=lambda x: x[0], reverse=True)[:beam_width]\n",
        "\n",
        "            # Check if all beams ended\n",
        "            if len(beams) == 0:\n",
        "                break\n",
        "\n",
        "        # Add remaining beams to completed\n",
        "        for score, seq in beams:\n",
        "            completed_beams.append((score / len(seq[0]), seq))\n",
        "\n",
        "        # Return best sequence\n",
        "        if not completed_beams:\n",
        "            return \"\"\n",
        "\n",
        "        best_seq = max(completed_beams, key=lambda x: x[0])[1][0, 1:]\n",
        "\n",
        "        # Remove EOS token\n",
        "        if (best_seq == EOS).any():\n",
        "            eos_idx = (best_seq == EOS).nonzero(as_tuple=True)[0][0]\n",
        "            best_seq = best_seq[:eos_idx]\n",
        "\n",
        "        return sp.decode(best_seq.tolist())\n",
        "\n",
        "# Test both decoding methods\n",
        "print(\"=\" * 60)\n",
        "print(\"Testing Decoding Methods\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "test_inputs = [\n",
        "    \"Ø³Ù„Ø§Ù…\",\n",
        "    \"Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\",\n",
        "    \"Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\"\n",
        "]\n",
        "\n",
        "for inp in test_inputs:\n",
        "    print(f\"\\nInput: {inp}\")\n",
        "    print(f\"  Greedy: {greedy_decode(inp)}\")\n",
        "    print(f\"  Beam:   {beam_search_decode(inp, beam_width=3)}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "bej2_ONlZIbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776d5926-d7d6-4905-cfbf-499154994bfc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Testing Decoding Methods\n",
            "============================================================\n",
            "\n",
            "Input: Ø³Ù„Ø§Ù…\n",
            "  Greedy: ÛŒÛ\n",
            "  Beam:   Ø¬Ø¨\n",
            "\n",
            "Input: Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’\n",
            "  Greedy: Ú©ÛŒØ§ ÛÛ’\n",
            "  Beam:   Ú©ÛŒØ§ ÛÛ’\n",
            "\n",
            "Input: Ø¢Ù¾ Ú©Ø§ Ù†Ø§Ù… Ú©ÛŒØ§ ÛÛ’\n",
            "  Greedy: Ø§Ù¾ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ú©ÛŒØ§ ÛÛ’\n",
            "  Beam:   Ø§Ù¾ Ú©Ø§ Ø³Ø¨ Ø³Û’ Ú©ÛŒØ§ ÛÛ’\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lxulK9FYOn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Human Evaluation**"
      ],
      "metadata": {
        "id": "KUGkXOH9YvWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def human_eval_interface():\n",
        "    \"\"\"Interactive human evaluation of generated responses\"\"\"\n",
        "\n",
        "    test_samples = random.sample(list(zip(X_test, y_test)), min(10, len(X_test)))\n",
        "\n",
        "    results = []\n",
        "    print(\"=\" * 60)\n",
        "    print(\" HUMAN EVALUATION\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Rate each response on a scale of 1-5 (5 = best)\")\n",
        "    print(\"  â€¢ Fluency: Grammar and naturalness\")\n",
        "    print(\"  â€¢ Relevance: Context matching\")\n",
        "    print(\"  â€¢ Adequacy: Completeness of response\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, (src, ref) in enumerate(test_samples):\n",
        "        gen = greedy_decode(src)\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Sample {i+1}/{len(test_samples)}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Input:     {src}\")\n",
        "        print(f\"Reference: {ref}\")\n",
        "        print(f\"Generated: {gen}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "        print(\"Rate the generated response:\")\n",
        "\n",
        "        try:\n",
        "            fluency = int(input(\"  Fluency (1-5): \"))\n",
        "            relevance = int(input(\"  Relevance (1-5): \"))\n",
        "            adequacy = int(input(\"  Adequacy (1-5): \"))\n",
        "\n",
        "            # Validate ratings\n",
        "            fluency = max(1, min(5, fluency))\n",
        "            relevance = max(1, min(5, relevance))\n",
        "            adequacy = max(1, min(5, adequacy))\n",
        "\n",
        "            results.append({\n",
        "                'input': src,\n",
        "                'reference': ref,\n",
        "                'generated': gen,\n",
        "                'fluency': fluency,\n",
        "                'relevance': relevance,\n",
        "                'adequacy': adequacy\n",
        "            })\n",
        "        except ValueError:\n",
        "            print(\" Invalid input. Using default score of 3.\")\n",
        "            results.append({\n",
        "                'input': src,\n",
        "                'reference': ref,\n",
        "                'generated': gen,\n",
        "                'fluency': 3,\n",
        "                'relevance': 3,\n",
        "                'adequacy': 3\n",
        "            })\n",
        "\n",
        "    # Calculate averages\n",
        "    avg_fluency = np.mean([r['fluency'] for r in results])\n",
        "    avg_relevance = np.mean([r['relevance'] for r in results])\n",
        "    avg_adequacy = np.mean([r['adequacy'] for r in results])\n",
        "    overall = (avg_fluency + avg_relevance + avg_adequacy) / 3\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\" HUMAN EVALUATION RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Average Fluency:   {avg_fluency:.2f}/5.00\")\n",
        "    print(f\"  Average Relevance: {avg_relevance:.2f}/5.00\")\n",
        "    print(f\"  Average Adequacy:  {avg_adequacy:.2f}/5.00\")\n",
        "    print(f\"  {'â”€'*60}\")\n",
        "    print(f\"  Overall Score:     {overall:.2f}/5.00\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "print(\"Starting human evaluation...\")\n",
        "print(\"(This requires manual input for each sample)\\n\")\n",
        "eval_results = human_eval_interface()"
      ],
      "metadata": {
        "id": "bXqeEbl_Ytlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e79bd1-9840-4293-8743-3b00241ae114"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting human evaluation...\n",
            "(This requires manual input for each sample)\n",
            "\n",
            "============================================================\n",
            " HUMAN EVALUATION\n",
            "============================================================\n",
            "Rate each response on a scale of 1-5 (5 = best)\n",
            "  â€¢ Fluency: Grammar and naturalness\n",
            "  â€¢ Relevance: Context matching\n",
            "  â€¢ Adequacy: Completeness of response\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Sample 1/10\n",
            "============================================================\n",
            "Input:     Ú©Ø±Ù† Ù…ÛŒÚº Ú©ÛÙ„ Ú©Ø± Ø¨Ø§Øª Ú©ÛŒ ÛÛ’ [SEP] ÛŒÙ‚ÛŒÙ† Ú©Ø±ØªØ§ ÛÙˆÚº Ú©Û’ Ù„ÙˆÚ¯ Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø·ÙˆØ± Ù¾Ø± Ù…ÛØ°Ø¨ ÛÙˆØªÛ’ ÛÛŒÚº\n",
            "Reference: ÙˆÙØ§Ù‚ÛŒ ÙˆØ²ÛŒØ± Ú©ÛŒ ÛØ¯Ø§ÛŒØª Ù¾Ø± Ø¨Ø¬Ù„ÛŒ ØªÙ‚Ø³ÛŒÙ… Ú©Ø§Ø± Ú©Ù…Ù¾Ù†ÛŒÙˆÚº Ú©ÛŒ Ø¬Ø§Ù†Ø¨ Ø³Û’Ø®ØµÙˆØµÛŒ ÛÙ†Ú¯Ø§Ù…ÛŒ Ø±ÙˆÙ…Ø² Ú©Ø§ Ù‚ÛŒØ§Ù…\n",
            "Generated: ÛŒÛ Ø¨Ø§Øª ÛÛ’ Ú©Û ÙˆÛ Ø§Ø³ Ú©Û’ Ù„ÛŒÛ’ Ù…ÛŒÚº Ø¨ÛØª Ú©Ù… ÛÛ’.\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 2/10\n",
            "============================================================\n",
            "Input:     Ø¬Ùˆ Ø§Ø³ [MASK0] [MASK1] ÙˆÛ Ø§ÛŒØ³Û’ ØªÛØ§ Ø¬ÛŒØ³Û’ Ù‚Ø§Ù†ÙˆÙ† Ú©Ùˆ Ø§Ù¾Ù†Û’ ÛØ§ØªÛÙˆÚº Ù…ÛŒÚº Ù„ÛŒÙ†Ø§\n",
            "Reference: [SPAN0] Ù†Û’ [SPAN1] Ú©ÛŒØ§\n",
            "Generated: [SPAN0] Ø¬Ùˆ ÙˆÛ\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 3/10\n",
            "============================================================\n",
            "Input:     Ù„ÛÙˆ Ø±Ù†Ú¯ ÛÙˆÙ†Û’ Ú©Û’ ### Ù†ÛØ§ÛŒØª ØªÚ©Ù„ÛŒÙ Ø¯Û ÛÛ’\n",
            "Reference: [POS4] Ø³Ø§ØªÛ\n",
            "Generated: Ø¬Ø¨ ØªÚ© Ú©Û’ Ù„ÛŒÛ’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªØ§ ÛÛ’\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 4/10\n",
            "============================================================\n",
            "Input:     Ø§Ù† ÚˆØ§Ú©ÙˆÙˆÚº Ú©Û’ Ù¾Ø§Ø³ Ø¨ÛØ§Ø±ÛŒ Ø§Ø³Ù„Ø­Û Ú©ÛØ§Úº Ø³Û’ Ø§ØªØ§ ÛÛ’ ÛŒÛ [CONTINUE]\n",
            "Reference: Ø§Ø³Ù„Ø­Û ÛŒÛØ§Úº ØªÙˆ Ù†ÛÛŒÚº Ø¨Ù†ØªØ§\n",
            "Generated: Ø§Ù† Ú©Û’ Ø³Ø§ØªÛ Ø³Ø§ØªÛ Ú©ÛŒØ§ ÛÛ’?\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 2\n",
            "  Adequacy (1-5): 3\n",
            "\n",
            "============================================================\n",
            "Sample 5/10\n",
            "============================================================\n",
            "Input:     Ù…ÛŒÙ¹ÛÛ’ [MASK1] Ø®Ø¯ÙˆØ®Ø§Ù„ Ø§ÙˆØ± Ù¾Ú©Ø§Ù†Û’ Ú©ÛŒ [MASK0] Ù¾Ø± Ø±ÙˆØ´Ù†ÛŒ ÚˆØ§Ù„ÛŒ\n",
            "Reference: [SPAN1] Ø§Ù…Ù„ÛŒÙ¹ Ú©Û’ [SPAN0] ØªØ±Ú©ÛŒØ¨\n",
            "Generated: [SPAN0] Ù¾Ø± Ù¾Ø§Ø¨Ù†Ø¯ÛŒ\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 6/10\n",
            "============================================================\n",
            "Input:     Ø³Ø§Ø¨Ù‚ Ø³ÛŒÚ©Ø±Ù¹Ø±ÛŒ Ø®Ø²Ø§Ù†Û Ø·Ø§Ø±Ù‚ Ø¨Ø§Ø¬ÙˆÛ Ú¯ÙˆØ±Ù†Ø± [MASK0]\n",
            "Reference: [SPAN0] Ø§Ø³Ù¹ÛŒÙ¹ Ø¨ÛŒÙ†Ú© ØªØ¹ÛŒÙ†Ø§Øª\n",
            "Generated: [SPAN0] Ú©ÛŒ Ø¬Ø§Ù†Ø¨\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 7/10\n",
            "============================================================\n",
            "Input:     [MASK0] Ø§Ø³ Ú©ÛŒ [MASK1] Ø§Ù¾ ÛÛŒ Ú©ÛŒÙ„ÛŒÛ’ ÛÛŒÚº\n",
            "Reference: [SPAN0] Ø§ÙˆØ± [SPAN1] ÙˆØ¶Ø§Ø­Øª\n",
            "Generated: [SPAN0] Ø§Ù¾ Ú©ÛŒ Ø§Ù¾ ÛÛŒ\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 8/10\n",
            "============================================================\n",
            "Input:     Ø§ÛŒØ³Û’ Ù„Ù…Ø­ÙˆÚº Ù…ÛŒÚº Ø®ÙˆØ¯ Ú©Ùˆ Ø³Ù†Ø¨ÛØ§Ù„Ù†Û’ Ú©ÛŒ [CONTINUE]\n",
            "Reference: Ø¶Ø±ÙˆØ±Øª ÛÙˆØªÛŒ ÛÛ’.\n",
            "Generated: Ú©ÛŒ Ø¬Ø§Ù†Ø¨ Ø³Û’ Ù…Ù„Ø§Ù‚Ø§Øª\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 9/10\n",
            "============================================================\n",
            "Input:     ÛÙ…ÛŒÚº Ú©ÙˆÛŒÛŒ Ù„ÛŒ Ú©ÙˆØ§Ù† [MASK0] Ú©Ø¨ [MASK1] ÛÙˆÚ¯Ø§?\n",
            "Reference: [SPAN0] ÛŒÙˆ [SPAN1] Ù†ØµÛŒØ¨\n",
            "Generated: [SPAN0] Ú©ÛŒØ§ ÛŒÛ\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 1\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            "Sample 10/10\n",
            "============================================================\n",
            "Input:     ØªØ±ØºÛŒØ¨ Ú©Û’ Ø§Ø«Ø±Ø§Øª Ø³Û’ Ø¨ÛŒÙ…Ø§Ø±ÛŒÙˆÚº Ø³Û’ Ø¨ÛÛŒ Ú†ÛÙ¹Ú©Ø§Ø±Ø§ Ø­Ø§ØµÙ„ [CONTINUE]\n",
            "Reference: Ú©ÛŒØ§ Ø¬Ø§Ø³Ú©ØªØ§ ÛÛ’ Ø¬ÛŒØ³Û’ Ú©ÛŒÙ†Ø³Ø±\n",
            "Generated: Ø³Û’ Ù¾ÛÙ„Û’ Ø³Û’ Ø¨ÛÛŒ Ù…Ø­Ø³ÙˆØ³ Ú©Ø±ØªØ§ ÛÙˆÚº\n",
            "------------------------------------------------------------\n",
            "Rate the generated response:\n",
            "  Fluency (1-5): 2\n",
            "  Relevance (1-5): 1\n",
            "  Adequacy (1-5): 1\n",
            "\n",
            "============================================================\n",
            " HUMAN EVALUATION RESULTS\n",
            "============================================================\n",
            "  Average Fluency:   1.10/5.00\n",
            "  Average Relevance: 1.10/5.00\n",
            "  Average Adequacy:  1.20/5.00\n",
            "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "  Overall Score:     1.13/5.00\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor(); sp.load(\"spm/urdu.model\")\n",
        "print(\"piece_size:\", sp.get_piece_size() if hasattr(sp,\"get_piece_size\") else sp.GetPieceSize())\n",
        "print(\"BOS/EOS/UNK/PAD:\", sp.bos_id(), sp.eos_id(), sp.unk_id(), getattr(sp,'pad_id',lambda:-1)())\n",
        "\n",
        "# sanity round-trip\n",
        "txt = \"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…ØŒ Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ\"\n",
        "ids = sp.encode(txt, out_type=int)\n",
        "print(\"encoded len:\", len(ids))\n",
        "print(\"decoded:\", sp.decode(ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K1eI23IU70x",
        "outputId": "ccc15411-f04e-447b-8c59-3655320656db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "piece_size: 20000\n",
            "BOS/EOS/UNK/PAD: 1 2 3 0\n",
            "encoded len: 11\n",
            "decoded: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù… â‡   â‡ Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚº â‡ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install streamlit sentencepiece requests pyngrok==7.1.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOuvMgByX_uX",
        "outputId": "c3eea5e4-97dd-4965-f3a0-8f58fdfc797d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "=============================================================================\n",
        "ğŸ“± URDU CHATBOT - STREAMLIT DEPLOYMENT (CLOUDFLARE TUNNEL)\n",
        "=============================================================================\n",
        "Alternative method using Cloudflare (no signup needed, more reliable)\n",
        "Run this cell to deploy your Urdu chatbot with a public URL\n",
        "=============================================================================\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: INSTALL DEPENDENCIES\n",
        "# ============================================================\n",
        "print(\"ğŸ“¦ Installing dependencies...\")\n",
        "!pip install -q streamlit sentencepiece\n",
        "\n",
        "# Download cloudflared binary\n",
        "!wget -q -O /usr/local/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x /usr/local/bin/cloudflared\n",
        "\n",
        "print(\"âœ… Dependencies installed\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: WRITE STREAMLIT APP (Same as before)\n",
        "# ============================================================\n",
        "print(\"\\nğŸ“ Creating Streamlit app...\")\n",
        "\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sentencepiece as spm\n",
        "import math\n",
        "import json\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Ø§Ø±Ø¯Ùˆ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹ | Urdu Chatbot\",\n",
        "    page_icon=\"ğŸ’¬\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    @import url('https://fonts.googleapis.com/css2?family=Noto+Nastaliq+Urdu:wght@400;700&display=swap');\n",
        "    .rtl {\n",
        "        direction: rtl;\n",
        "        text-align: right;\n",
        "        font-family: 'Noto Nastaliq Urdu', serif;\n",
        "        line-height: 2.0;\n",
        "    }\n",
        "    .user-message {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        padding: 15px 20px;\n",
        "        border-radius: 18px 18px 4px 18px;\n",
        "        margin: 10px 0;\n",
        "        max-width: 75%;\n",
        "        float: right;\n",
        "        clear: both;\n",
        "    }\n",
        "    .bot-message {\n",
        "        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
        "        color: white;\n",
        "        padding: 15px 20px;\n",
        "        border-radius: 18px 18px 18px 4px;\n",
        "        margin: 10px 0;\n",
        "        max-width: 75%;\n",
        "        float: left;\n",
        "        clear: both;\n",
        "    }\n",
        "    .chat-container {\n",
        "        background: #f8f9fa;\n",
        "        padding: 20px;\n",
        "        border-radius: 15px;\n",
        "        min-height: 500px;\n",
        "        max-height: 600px;\n",
        "        overflow-y: auto;\n",
        "    }\n",
        "    .stTextArea textarea {\n",
        "        font-family: 'Noto Nastaliq Urdu', serif;\n",
        "        direction: rtl;\n",
        "        text-align: right;\n",
        "        font-size: 16px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Text normalization\n",
        "ZW_RE = re.compile(r\"[\\\\u200c\\\\u200d]\")\n",
        "TAT_RE = re.compile(r\"\\\\u0640\")\n",
        "DIAC_RE = re.compile(r\"[\\\\u064B-\\\\u0652\\\\u0670\\\\u0653-\\\\u065F\\\\u06D6-\\\\u06ED]\")\n",
        "LETTER_MAP = {\"Ø£\":\"Ø§\",\"Ø¥\":\"Ø§\",\"Ø¢\":\"Ø§\",\"ÙŠ\":\"ÛŒ\",\"Ù‰\":\"ÛŒ\",\"Ø¦\":\"ÛŒ\",\"Ø©\":\"Û\",\"Ùƒ\":\"Ú©\"}\n",
        "PUNCT_MAP = {\"ØŒ\":\",\",\"Ø›\":\";\",\"Û”\":\".\",\"ØŸ\":\"?\"}\n",
        "E2W = str.maketrans(\"Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹\",\"0123456789\")\n",
        "\n",
        "def normalize_urdu(text):\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    s = unicodedata.normalize(\"NFKC\", text)\n",
        "    s = ZW_RE.sub(\"\", s)\n",
        "    s = TAT_RE.sub(\"\", s)\n",
        "    s = DIAC_RE.sub(\"\", s)\n",
        "    for k,v in LETTER_MAP.items(): s = s.replace(k,v)\n",
        "    for k,v in PUNCT_MAP.items(): s = s.replace(k,v)\n",
        "    s = s.translate(E2W)\n",
        "    return re.sub(r\"\\\\s+\", \" \", s).strip()\n",
        "\n",
        "# Model architecture\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1024):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, vocab, d_model=512, nhead=8, enc_layers=4, dec_layers=4, ff=2048, drop=0.1):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(vocab, d_model, padding_idx=0)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.pos_dec = PositionalEncoding(d_model)\n",
        "        self.tf = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=enc_layers,\n",
        "                                num_decoder_layers=dec_layers, dim_feedforward=ff,\n",
        "                                dropout=drop, batch_first=True)\n",
        "        self.fc_out = nn.Linear(d_model, vocab)\n",
        "    def forward(self, src_ids, tgt_in_ids, src_kpm, tgt_kpm, tgt_causal):\n",
        "        src = self.pos_enc(self.tok_emb(src_ids))\n",
        "        tgt = self.pos_dec(self.tok_emb(tgt_in_ids))\n",
        "        out = self.tf(src, tgt, src_key_padding_mask=src_kpm, tgt_key_padding_mask=tgt_kpm,\n",
        "                     memory_key_padding_mask=src_kpm, tgt_mask=tgt_causal)\n",
        "        return self.fc_out(out)\n",
        "\n",
        "# Decoding\n",
        "@torch.no_grad()\n",
        "def greedy_decode(model, sp, text, max_len=64, device='cpu', PAD=0, BOS=1, EOS=2, normalize=True):\n",
        "    model.eval()\n",
        "    processed_text = normalize_urdu(text) if normalize else text\n",
        "    src_tokens = sp.encode(processed_text, out_type=int)\n",
        "    if len(src_tokens) > 94: src_tokens = src_tokens[:94]\n",
        "    src_ids = torch.tensor([[BOS] + src_tokens + [EOS]], dtype=torch.long, device=device)\n",
        "    src_kpm = (src_ids == PAD)\n",
        "    ys = torch.tensor([[BOS]], dtype=torch.long, device=device)\n",
        "    for _ in range(max_len):\n",
        "        T = ys.size(1)\n",
        "        causal = torch.triu(torch.ones(T, T, dtype=torch.bool, device=device), diagonal=1)\n",
        "        logits = model(src_ids, ys, src_kpm, (ys == PAD), causal)\n",
        "        next_id = logits[:, -1, :].argmax(-1)\n",
        "        ys = torch.cat([ys, next_id.unsqueeze(1)], dim=1)\n",
        "        if next_id.item() == EOS: break\n",
        "    out = ys[0, 1:]\n",
        "    if (out == EOS).any():\n",
        "        eos_idx = (out == EOS).nonzero(as_tuple=True)[0][0]\n",
        "        out = out[:eos_idx]\n",
        "    return sp.decode(out.tolist())\n",
        "\n",
        "@torch.no_grad()\n",
        "def beam_search_decode(model, sp, text, beam_width=4, max_len=64, device='cpu', PAD=0, BOS=1, EOS=2, normalize=True):\n",
        "    model.eval()\n",
        "    processed_text = normalize_urdu(text) if normalize else text\n",
        "    src_tokens = sp.encode(processed_text, out_type=int)\n",
        "    if len(src_tokens) > 94: src_tokens = src_tokens[:94]\n",
        "    src_ids = torch.tensor([[BOS] + src_tokens + [EOS]], dtype=torch.long, device=device)\n",
        "    src_kpm = (src_ids == PAD)\n",
        "    beams = [(0.0, torch.tensor([[BOS]], device=device))]\n",
        "    completed_beams = []\n",
        "    for step in range(max_len):\n",
        "        candidates = []\n",
        "        for score, seq in beams:\n",
        "            if seq[0, -1].item() == EOS:\n",
        "                completed_beams.append((score / len(seq[0]), seq))\n",
        "                continue\n",
        "            T = seq.size(1)\n",
        "            causal = torch.triu(torch.ones(T, T, dtype=torch.bool, device=device), diagonal=1)\n",
        "            logits = model(src_ids, seq, src_kpm, (seq == PAD), causal)\n",
        "            log_probs = F.log_softmax(logits[:, -1, :], dim=-1)\n",
        "            topk_probs, topk_ids = torch.topk(log_probs, beam_width)\n",
        "            for prob, token_id in zip(topk_probs[0], topk_ids[0]):\n",
        "                new_seq = torch.cat([seq, token_id.unsqueeze(0).unsqueeze(0)], dim=1)\n",
        "                candidates.append((score + prob.item(), new_seq))\n",
        "        beams = sorted(candidates, key=lambda x: x[0], reverse=True)[:beam_width]\n",
        "        if len(beams) == 0: break\n",
        "    for score, seq in beams:\n",
        "        completed_beams.append((score / len(seq[0]), seq))\n",
        "    if not completed_beams: return \"\"\n",
        "    best_seq = max(completed_beams, key=lambda x: x[0])[1][0, 1:]\n",
        "    if (best_seq == EOS).any():\n",
        "        eos_idx = (best_seq == EOS).nonzero(as_tuple=True)[0][0]\n",
        "        best_seq = best_seq[:eos_idx]\n",
        "    return sp.decode(best_seq.tolist())\n",
        "\n",
        "# Load model\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer(model_path, tokenizer_path, device):\n",
        "    try:\n",
        "        sp = spm.SentencePieceProcessor()\n",
        "        sp.load(tokenizer_path)\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        vocab_size = checkpoint.get('vocab_size', sp.get_piece_size())\n",
        "        if 'config' in checkpoint:\n",
        "            config = checkpoint['config']\n",
        "            model = Seq2SeqTransformer(vocab=vocab_size, d_model=config.get('d_model', 512),\n",
        "                                      nhead=config.get('nhead', 2), enc_layers=config.get('enc_layers', 2),\n",
        "                                      dec_layers=config.get('dec_layers', 2), ff=config.get('ff', 2048),\n",
        "                                      drop=config.get('dropout', 0.1))\n",
        "        else:\n",
        "            model = Seq2SeqTransformer(vocab=vocab_size, d_model=512, nhead=2, enc_layers=2,\n",
        "                                      dec_layers=2, ff=2048, drop=0.1)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        return model, sp, None\n",
        "    except Exception as e:\n",
        "        return None, None, str(e)\n",
        "\n",
        "# Session state\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "if 'message_count' not in st.session_state:\n",
        "    st.session_state.message_count = 0\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    st.markdown(\"### âš™ï¸ Settings\")\n",
        "    model_path = st.text_input(\"Model Path\", \"/content/best_bleu_urdu_chatbot.pt\")\n",
        "    tokenizer_path = st.text_input(\"Tokenizer Path\", \"/content/spm/urdu.model\")\n",
        "    device = st.selectbox(\"Device\", [\"cuda\" if torch.cuda.is_available() else \"cpu\", \"cpu\"])\n",
        "    st.markdown(\"---\")\n",
        "    decode_strategy = st.radio(\"Decoding\", [\"Greedy\", \"Beam Search\"])\n",
        "    if decode_strategy == \"Beam Search\":\n",
        "        beam_width = st.slider(\"Beam Width\", 2, 10, 4)\n",
        "    else:\n",
        "        beam_width = 1\n",
        "    max_length = st.slider(\"Max Length\", 32, 128, 64, 8)\n",
        "    normalize_input = st.checkbox(\"Normalize Input\", value=True)\n",
        "    with st.expander(\"Token IDs\"):\n",
        "        PAD = st.number_input(\"PAD\", value=0, step=1)\n",
        "        BOS = st.number_input(\"BOS\", value=1, step=1)\n",
        "        EOS = st.number_input(\"EOS\", value=2, step=1)\n",
        "    st.markdown(\"---\")\n",
        "    if st.button(\"ğŸ—‘ï¸ Clear Chat\", use_container_width=True):\n",
        "        st.session_state.chat_history = []\n",
        "        st.session_state.message_count = 0\n",
        "        st.rerun()\n",
        "\n",
        "# Main UI\n",
        "st.markdown('<h1 style=\"text-align:center;\">ğŸ’¬ Ø§Ø±Ø¯Ùˆ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹</h1>', unsafe_allow_html=True)\n",
        "\n",
        "with st.spinner(\"Loading...\"):\n",
        "    model, sp, error = load_model_and_tokenizer(model_path, tokenizer_path, device)\n",
        "\n",
        "if error:\n",
        "    st.error(f\"Error: {error}\")\n",
        "    st.stop()\n",
        "\n",
        "st.success(f\"âœ… Model loaded on {device}\")\n",
        "\n",
        "st.markdown('<div class=\"chat-container\">', unsafe_allow_html=True)\n",
        "if not st.session_state.chat_history:\n",
        "    st.info(\"ğŸ‘‹ Ø³Ù„Ø§Ù…! Ú©ÛŒØ³Û’ Ù…Ø¯Ø¯ Ú©Ø± Ø³Ú©ØªØ§ ÛÙˆÚºØŸ\")\n",
        "else:\n",
        "    for user_msg, bot_msg in st.session_state.chat_history:\n",
        "        st.markdown(f'<div class=\"user-message rtl\"><b>Ø¢Ù¾:</b> {user_msg}</div><div style=\"clear:both;\"></div>',\n",
        "                   unsafe_allow_html=True)\n",
        "        st.markdown(f'<div class=\"bot-message rtl\"><b>Ø¨ÙˆÙ¹:</b> {bot_msg}</div><div style=\"clear:both;\"></div>',\n",
        "                   unsafe_allow_html=True)\n",
        "st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "col1, col2 = st.columns([5, 1])\n",
        "with col1:\n",
        "    user_input = st.text_area(\"\", height=100, placeholder=\"ÛŒÛØ§Úº Ù¹Ø§Ø¦Ù¾ Ú©Ø±ÛŒÚº...\", label_visibility=\"collapsed\")\n",
        "with col2:\n",
        "    st.markdown(\"<br>\", unsafe_allow_html=True)\n",
        "    send_button = st.button(\"ğŸ“¤ Send\", use_container_width=True, type=\"primary\")\n",
        "\n",
        "if send_button and user_input.strip():\n",
        "    with st.spinner(\"Generating...\"):\n",
        "        try:\n",
        "            if decode_strategy == \"Greedy\":\n",
        "                response = greedy_decode(model, sp, user_input, max_len=max_length, device=device,\n",
        "                                        PAD=PAD, BOS=BOS, EOS=EOS, normalize=normalize_input)\n",
        "            else:\n",
        "                response = beam_search_decode(model, sp, user_input, beam_width=beam_width, max_len=max_length,\n",
        "                                             device=device, PAD=PAD, BOS=BOS, EOS=EOS, normalize=normalize_input)\n",
        "            st.session_state.chat_history.append((user_input, response))\n",
        "            st.session_state.message_count += 2\n",
        "            st.rerun()\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {str(e)}\")\n",
        "'''\n",
        "\n",
        "with open('/content/streamlit_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"âœ… Streamlit app created\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: VERIFY FILES\n",
        "# ============================================================\n",
        "print(\"\\nğŸ“‚ Checking files...\")\n",
        "\n",
        "import os\n",
        "\n",
        "files_check = [\n",
        "    (\"/content/best_bleu_urdu_chatbot.pt\", \"Model\"),\n",
        "    (\"/content/spm/urdu.model\", \"Tokenizer\"),\n",
        "    (\"/content/streamlit_app.py\", \"App\")\n",
        "]\n",
        "\n",
        "for filepath, desc in files_check:\n",
        "    if os.path.exists(filepath):\n",
        "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
        "        print(f\"   âœ… {desc}: {size_mb:.2f} MB\")\n",
        "    else:\n",
        "        print(f\"   âŒ {desc}: NOT FOUND at {filepath}\")\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: START STREAMLIT\n",
        "# ============================================================\n",
        "print(\"\\nğŸš€ Starting Streamlit server...\")\n",
        "\n",
        "!pkill -f streamlit\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\n",
        "        \"streamlit\", \"run\", \"/content/streamlit_app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\"\n",
        "    ])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "print(\"â³ Waiting for server to start...\")\n",
        "time.sleep(8)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: CREATE CLOUDFLARE TUNNEL\n",
        "# ============================================================\n",
        "print(\"\\nğŸŒ Creating Cloudflare tunnel...\")\n",
        "\n",
        "import re\n",
        "import sys\n",
        "\n",
        "proc = subprocess.Popen(\n",
        "    [\"/usr/local/bin/cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8501\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "public_url = None\n",
        "timeout = 30\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"   Searching for tunnel URL...\", end=\"\", flush=True)\n",
        "\n",
        "while time.time() - start_time < timeout:\n",
        "    line = proc.stdout.readline()\n",
        "    if not line:\n",
        "        time.sleep(0.5)\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        continue\n",
        "\n",
        "    match = re.search(r\"https://[a-zA-Z0-9-]+\\.trycloudflare\\.com\", line)\n",
        "    if match:\n",
        "        public_url = match.group(0)\n",
        "        break\n",
        "\n",
        "print()  # New line after dots\n",
        "\n",
        "if public_url:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ğŸ‰ SUCCESS! Your Urdu Chatbot is LIVE!\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nğŸ”— PUBLIC URL:\")\n",
        "    print(f\"\\n   {public_url}\")\n",
        "    print(f\"\\nğŸ“± Click the link above or copy-paste it in your browser\")\n",
        "    print(f\"\\nâš ï¸  KEEP THIS CELL RUNNING!\")\n",
        "    print(f\"   â€¢ Stopping this cell will shut down the server\")\n",
        "    print(f\"   â€¢ The URL is temporary and changes each restart\")\n",
        "    print(f\"   â€¢ Share this link with anyone to test your chatbot\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"\\nğŸ“Š Server Status:\")\n",
        "    print(f\"   â€¢ Local:  http://localhost:8501\")\n",
        "    print(f\"   â€¢ Public: {public_url}\")\n",
        "    print(f\"   â€¢ Status: ğŸŸ¢ RUNNING\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"\\nğŸ’¡ Quick Tips:\")\n",
        "    print(\"   1. The chatbot supports Urdu RTL text rendering\")\n",
        "    print(\"   2. Try both Greedy and Beam Search decoding\")\n",
        "    print(\"   3. Adjust max length in sidebar for longer responses\")\n",
        "    print(\"   4. Use the Clear button to reset conversation\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"\\nğŸ“Œ For Permanent Deployment:\")\n",
        "    print(\"   â€¢ Option 1: Streamlit Cloud (free, recommended)\")\n",
        "    print(\"   â€¢ Option 2: Heroku, AWS, Google Cloud\")\n",
        "    print(\"   â€¢ Option 3: Docker + VPS\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    # Keep running\n",
        "    print(\"\\nâ¸ï¸  Server running. Press STOP button to shut down.\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nğŸ›‘ Shutting down...\")\n",
        "        proc.terminate()\n",
        "        print(\"âœ… Server stopped\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nâŒ Could not create tunnel URL\")\n",
        "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
        "    print(\"   1. Check internet connection\")\n",
        "    print(\"   2. Restart Colab runtime\")\n",
        "    print(\"   3. Try the ngrok version instead\")\n",
        "    print(\"\\nğŸ’¡ Alternative command:\")\n",
        "    print(\"   Run the first deployment cell with ngrok\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYCQ5rRuoLhm",
        "outputId": "881024d8-cd89-4bea-b6fb-66d5332916e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Installing dependencies...\n",
            "âœ… Dependencies installed\n",
            "\n",
            "ğŸ“ Creating Streamlit app...\n",
            "âœ… Streamlit app created\n",
            "\n",
            "ğŸ“‚ Checking files...\n",
            "   âœ… Model: 407.09 MB\n",
            "   âœ… Tokenizer: 0.60 MB\n",
            "   âœ… App: 0.01 MB\n",
            "\n",
            "ğŸš€ Starting Streamlit server...\n",
            "â³ Waiting for server to start...\n",
            "\n",
            "ğŸŒ Creating Cloudflare tunnel...\n",
            "   Searching for tunnel URL...\n",
            "\n",
            "================================================================================\n",
            "ğŸ‰ SUCCESS! Your Urdu Chatbot is LIVE!\n",
            "================================================================================\n",
            "\n",
            "ğŸ”— PUBLIC URL:\n",
            "\n",
            "   https://judy-leo-computational-attribute.trycloudflare.com\n",
            "\n",
            "ğŸ“± Click the link above or copy-paste it in your browser\n",
            "\n",
            "âš ï¸  KEEP THIS CELL RUNNING!\n",
            "   â€¢ Stopping this cell will shut down the server\n",
            "   â€¢ The URL is temporary and changes each restart\n",
            "   â€¢ Share this link with anyone to test your chatbot\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Server Status:\n",
            "   â€¢ Local:  http://localhost:8501\n",
            "   â€¢ Public: https://judy-leo-computational-attribute.trycloudflare.com\n",
            "   â€¢ Status: ğŸŸ¢ RUNNING\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ğŸ’¡ Quick Tips:\n",
            "   1. The chatbot supports Urdu RTL text rendering\n",
            "   2. Try both Greedy and Beam Search decoding\n",
            "   3. Adjust max length in sidebar for longer responses\n",
            "   4. Use the Clear button to reset conversation\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Œ For Permanent Deployment:\n",
            "   â€¢ Option 1: Streamlit Cloud (free, recommended)\n",
            "   â€¢ Option 2: Heroku, AWS, Google Cloud\n",
            "   â€¢ Option 3: Docker + VPS\n",
            "\n",
            "================================================================================\n",
            "\n",
            "â¸ï¸  Server running. Press STOP button to shut down.\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}